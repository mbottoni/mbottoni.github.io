
<!DOCTYPE html>
<html lang='en-US'>
<head>
  <meta charset='utf-8'>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Simple Reinforcement Learning Example</title>
  <meta name="description" content="A simple RL example, where i want an agent to navigate a grid to reach a goal while avoiding holes.
For more details here is the colab where I implemented the RL example Link to code">
  <link rel="icon" href="/favicon.png" type="image/png">
  <link rel="icon" href="/favicon.svg" type="image/svg+xml">
  <link rel="canonical" href="https://mbottoni.github.io/2024/08/04/simple_rl.html">
  <link rel="alternate" type="application/rss+xml" title="mbottoni" href="https://mbottoni.github.io/feed.xml">
  <style>
  @font-face {
    font-family: 'Open Sans'; src: url('/css/OpenSans-300-Normal.woff2') format('woff2');
    font-weight: 300; font-style: normal;
  }
  @font-face {
    font-family: 'JetBrains Mono'; src: url('/css/JetBrainsMono-400-Normal.woff2') format('woff2');
    font-weight: 400; font-style: normal;
  }
  @font-face {
    font-family: 'JetBrains Mono'; src: url('/css/JetBrainsMono-700-Normal.woff2') format('woff2');
    font-weight: 700; font-style: normal;
  }
  @font-face {
    font-family: 'EB Garamond'; src: url('/css/EBGaramond-400-Normal.woff2') format('woff2');
    font-weight: 400; font-style: normal;
  }
  @font-face {
    font-family: 'EB Garamond'; src: url('/css/EBGaramond-400-Italic.woff2') format('woff2');
    font-weight: 400; font-style: italic;
  }
  @font-face {
    font-family: 'EB Garamond'; src: url('/css/EBGaramond-700-Normal.woff2') format('woff2');
    font-weight: 700; font-style: normal;
  }
  @font-face {
    font-family: 'EB Garamond'; src: url('/css/EBGaramond-700-Italic.woff2') format('woff2');
    font-weight: 700; font-style: italic;
  }

  * { box-sizing: border-box; margin: 0; padding: 0; margin-block-start: 0; margin-block-end: 0; }

  body {
    max-width: 80ch;
    padding: 2ch;
    margin-left: auto;
    margin-right: auto;
  }

  header { margin-bottom: 2rem; }
  header > nav { display: flex; column-gap: 2ch; align-items: baseline; flex-wrap: wrap; }
  header a { font-style: normal; color: rgba(0, 0, 0, .8); text-decoration: none; }
  header a:hover { color: rgba(0, 0, 0, .8); text-decoration: underline; }
  header .title { font-size: 1.25em; flex-grow: 2; }

  footer { margin-top: 2rem; }
  footer > p { display: flex; column-gap: 2ch; justify-content: center; flex-wrap: wrap; }
  footer a { color: rgba(0, 0, 0, .8); text-decoration: none; white-space: nowrap; }
  footer i { vertical-align: middle; color: rgba(0, 0, 0, .8) }

  </style>

  <link rel="stylesheet" href="/css/main.css">
  
</head>

<body>
  <header>
    <nav>
      <a class="title" href="/">mbottoni</a>
      <a href="/about.html">About</a>
      <a href="/resume.html">Resume</a>
      <a href="/links.html">Links</a>
    </nav>
  </header>

  <main>
  <article >

    <h1>
    <a href="#Simple-Reinforcement-Learning-Example"><span>Simple Reinforcement Learning Example</span> <time datetime="2024-08-04">Aug 4, 2024</time></a>
    </h1>

<figure>

<img alt="" src="/assets/rl.png">
</figure>
<p><span>A simple RL example, where i want an agent to navigate a grid to reach a goal while avoiding holes.</span>
<span>For more details here is the colab where I implemented the RL example </span><a href="https://colab.research.google.com/drive/1hxqDEdurKZZUtJ2DTrEm1UQJwCJmQIhj?usp=sharing"><span>Link to code</span></a></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">import</span> gym</span>
<span class="line"><span class="hl-keyword">import</span> numpy <span class="hl-keyword">as</span> np</span>
<span class="line">env = gym.make(<span class="hl-string">&#x27;FrozenLake-v1&#x27;</span>, is_slippery=<span class="hl-literal">False</span>, render_mode=<span class="hl-string">&#x27;human&#x27;</span>)</span>
<span class="line"></span>
<span class="line">num_episodes = <span class="hl-number">1000</span></span>
<span class="line">max_steps_per_episode = <span class="hl-number">100</span></span>
<span class="line">learning_rate = <span class="hl-number">0.1</span></span>
<span class="line">discount_rate = <span class="hl-number">0.99</span></span>
<span class="line">exploration_rate = <span class="hl-number">1.0</span></span>
<span class="line">max_exploration_rate = <span class="hl-number">1.0</span></span>
<span class="line">min_exploration_rate = <span class="hl-number">0.01</span></span>
<span class="line">exploration_decay_rate = <span class="hl-number">0.001</span></span>
<span class="line"></span>
<span class="line">q_table = np.zeros((env.observation_space.n, env.action_space.n)) <span class="hl-comment"># q table</span></span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">for</span> episode <span class="hl-keyword">in</span> <span class="hl-built_in">range</span>(num_episodes):</span>
<span class="line">    state = env.reset()</span>
<span class="line">    done = <span class="hl-literal">False</span></span>
<span class="line">    step = <span class="hl-number">0</span></span>
<span class="line"></span>
<span class="line">    <span class="hl-keyword">for</span> step <span class="hl-keyword">in</span> <span class="hl-built_in">range</span>(max_steps_per_episode):</span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        <span class="hl-comment"># Exploration-exploitation trade-off</span></span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        exploration_threshold = np.random.uniform(<span class="hl-number">0</span>, <span class="hl-number">1</span>)</span>
<span class="line">        <span class="hl-keyword">if</span> exploration_threshold &gt; exploration_rate:</span>
<span class="line">            action = np.argmax(q_table[state, :])</span>
<span class="line">        <span class="hl-keyword">else</span>:</span>
<span class="line">            action = env.action_space.sample()</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        <span class="hl-comment"># Take the action and observe the outcome</span></span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        new_state, reward, done, info = env.step(action)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        <span class="hl-comment"># Update Q-table</span></span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        q_table[state, action] = q_table[state, action] + learning_rate * (reward + discount_rate * np.<span class="hl-built_in">max</span>(q_table[new_state, :]) - q_table[state, action])</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        <span class="hl-comment"># Transition to the new state</span></span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        state = new_state</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        <span class="hl-comment"># If the episode is done, break the loop</span></span>
<span class="line">        <span class="hl-comment">#</span></span>
<span class="line">        <span class="hl-keyword">if</span> done:</span>
<span class="line">            <span class="hl-keyword">break</span></span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment">#</span></span>
<span class="line">    <span class="hl-comment"># Decay the exploration rate</span></span>
<span class="line">    <span class="hl-comment">#</span></span>
<span class="line">    exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate * episode)</span>
<span class="line"></span>
<span class="line"></span>
<span class="line">state = env.reset()</span>
<span class="line">env.render()</span>
<span class="line">done = <span class="hl-literal">False</span></span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">while</span> <span class="hl-keyword">not</span> done:</span>
<span class="line">    action = np.argmax(q_table[state, :])</span>
<span class="line">    new_state, reward, done, info = env.step(action)</span>
<span class="line">    state = new_state</span>
<span class="line">    env.render()</span>
<span class="line"></span>
<span class="line"><span class="hl-built_in">print</span>(<span class="hl-string">&quot;Test completed.&quot;</span>)</span></code></pre>

</figure>
</article>
  </main>

  <footer class="site-footer">
    <p>
      <a href="https://github.com/mbottoni/mbottoni.github.io/edit/master/content/posts/2024-08-04-simple_rl.dj">
        <svg class="icon"><use href="/assets/icons.svg#edit"/></svg>
        Fix typo
      </a>
      <a href="/feed.xml">
        <svg class="icon"><use href="/assets/icons.svg#rss"/></svg>
        Subscribe
      </a>
      <a href="mailto:maruanbakriottoni@gmail.com">
        <svg class="icon"><use href="/assets/icons.svg#email"/></svg>
        Get in touch
      </a>
      <a href="https://github.com/mbottoni">
        <svg class="icon"><use href="/assets/icons.svg#github"/></svg>
        mbottoni
      </a>
    </p>
  </footer>
</body>

</html>
