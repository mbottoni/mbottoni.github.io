
<!DOCTYPE html>
<html lang='en-US'>
<head>
  <meta charset='utf-8'>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Flow Matching, a short overview</title>
  <meta name="description" content="In summary, flow matching is a generative modeling technique that provides 
an elegant way to transform data distributions.">
  <link rel="icon" href="/favicon.png" type="image/png">
  <link rel="icon" href="/favicon.svg" type="image/svg+xml">
  <link rel="canonical" href="https://mbottoni.github.io/2024/12/01/flow.html">
  <link rel="alternate" type="application/rss+xml" title="mbottoni" href="https://mbottoni.github.io/feed.xml">
  <style>
  @font-face {
    font-family: 'Open Sans'; src: url('/css/OpenSans-300-Normal.woff2') format('woff2');
    font-weight: 300; font-style: normal;
  }
  @font-face {
    font-family: 'JetBrains Mono'; src: url('/css/JetBrainsMono-400-Normal.woff2') format('woff2');
    font-weight: 400; font-style: normal;
  }
  @font-face {
    font-family: 'JetBrains Mono'; src: url('/css/JetBrainsMono-700-Normal.woff2') format('woff2');
    font-weight: 700; font-style: normal;
  }
  @font-face {
    font-family: 'EB Garamond'; src: url('/css/EBGaramond-400-Normal.woff2') format('woff2');
    font-weight: 400; font-style: normal;
  }
  @font-face {
    font-family: 'EB Garamond'; src: url('/css/EBGaramond-400-Italic.woff2') format('woff2');
    font-weight: 400; font-style: italic;
  }
  @font-face {
    font-family: 'EB Garamond'; src: url('/css/EBGaramond-700-Normal.woff2') format('woff2');
    font-weight: 700; font-style: normal;
  }
  @font-face {
    font-family: 'EB Garamond'; src: url('/css/EBGaramond-700-Italic.woff2') format('woff2');
    font-weight: 700; font-style: italic;
  }

  * { box-sizing: border-box; margin: 0; padding: 0; margin-block-start: 0; margin-block-end: 0; }

  body {
    max-width: 80ch;
    padding: 2ch;
    margin-left: auto;
    margin-right: auto;
  }

  header { margin-bottom: 2rem; }
  header > nav { display: flex; column-gap: 2ch; align-items: baseline; flex-wrap: wrap; }
  header a { font-style: normal; color: rgba(0, 0, 0, .8); text-decoration: none; }
  header a:hover { color: rgba(0, 0, 0, .8); text-decoration: underline; }
  header .title { font-size: 1.25em; flex-grow: 2; }

  footer { margin-top: 2rem; }
  footer > p { display: flex; column-gap: 2ch; justify-content: center; flex-wrap: wrap; }
  footer a { color: rgba(0, 0, 0, .8); text-decoration: none; white-space: nowrap; }
  footer i { vertical-align: middle; color: rgba(0, 0, 0, .8) }

  .theme-grid { display: grid; gap: 2rem; grid-template-columns: repeat(auto-fit, minmax(16rem, 1fr)); }
  .theme-card { border: 1px solid rgba(0,0,0,.12); border-radius: 1rem; padding: 1.5rem; display: flex; flex-direction: column; gap: .75rem; }
  .theme-card h2 { font-size: 1.35em; }
  .theme-card h2 a { text-decoration: none; color: #b32f1c; }
  .theme-card h2 a:hover { text-decoration: underline; }
  .theme-card p { color: rgba(0,0,0,.75); line-height: 1.5; }
  .theme-meta { font-size: .85em; color: rgba(0,0,0,.6); }

  .theme-page header h1 { font-size: 2em; margin-bottom: .5rem; }
  .theme-page header p { color: rgba(0,0,0,.65); line-height: 1.5; }
  .theme-page { display: flex; flex-direction: column; gap: 1.5rem; }

  .post-list { list-style: none; display: flex; flex-direction: column; gap: 1.5rem; padding: 0; }
  .post-card { display: grid; gap: 1rem; grid-template-columns: minmax(0, 1fr); }
  .post-card__media { display: none; }
  .post-card__body h3 { font-size: 1.1em; margin-bottom: .35rem; }
  .post-card__body p { color: rgba(0, 0, 0, .7); }
  .post-card__media a { display: block; border-radius: .75rem; overflow: hidden; }
  .post-card__media img { width: 100%; height: 100%; object-fit: cover; display: block; }
  @media (min-width: 720px) {
    .post-card { grid-template-columns: 260px 1fr; align-items: center; }
    .post-card__media { display: block; min-height: 160px; }
    .post-card__media:empty { display: block; }
  }

  .theme-pill, .theme-banner a { display: inline-flex; align-items: center; gap: .4rem; font-size: .8em; text-transform: uppercase; letter-spacing: .08em; border: 1px solid rgba(0, 0, 0, .15); border-radius: 999px; padding: .25rem .9rem; text-decoration: none; color: rgba(0, 0, 0, .7); }
  .theme-pill svg, .theme-banner svg { width: .75em; height: .75em; }
  .theme-banner { margin-bottom: 1rem; }
  .theme-banner span { font-size: .8em; color: rgba(0, 0, 0, .6); margin-right: .5rem; }
  
  .katex { font-size: 0.95em !important; color: rgba(0, 0, 0, 0.9); }
  .katex-display { margin: 0.5em 0; overflow-x: auto; overflow-y: hidden; }

  </style>

  <link rel="stylesheet" href="/css/main.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
</head>

<body>
  <header>
    <nav>
      <a class="title" href="/">mbottoni</a>
      <a href="/about.html">About</a>
      <a href="/resume.html">Resume</a>
      <a href="/repositories.html">Repositories</a>
      <a href="/links.html">Links</a>
    </nav>
  </header>

  <main>
  
      <div class="theme-banner">
        <span>Filed under</span>
        <a class="theme-pill" href="/themes/generative.html">
          Diffusion &amp; Generative Modeling
        </a>
      </div>
      <article >

    <h1>
    <a href="#Flow-Matching-a-short-overview"><span>Flow Matching, a short overview</span> <time datetime="2024-12-01">Dec 1, 2024</time></a>
    </h1>

<figure>

<img alt="" src="/assets/generative/flow.png">
</figure>
<p><span>In summary, flow matching is a generative modeling technique that provides </span>
<span>an elegant way to transform data distributions.</span></p>

<figure class="code-block">


<pre><code><span class="line"></span>
<span class="line"><span class="hl-keyword">import</span> numpy <span class="hl-keyword">as</span> np</span>
<span class="line"><span class="hl-keyword">import</span> torch</span>
<span class="line"><span class="hl-keyword">import</span> torch.nn <span class="hl-keyword">as</span> nn</span>
<span class="line"><span class="hl-keyword">import</span> torch.optim <span class="hl-keyword">as</span> optim</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">class</span> <span class="hl-title class_">FlowMatchingModel</span>:</span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">__init__</span>(<span class="hl-params">self, input_dim, hidden_dim</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Initialize Flow Matching Model</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            input_dim (int): Dimension of input data</span></span>
<span class="line"><span class="hl-string">            hidden_dim (int): Dimension of hidden layers</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        self.base_distribution = <span class="hl-literal">None</span>  <span class="hl-comment"># Initial data distribution</span></span>
<span class="line">        self.target_distribution = <span class="hl-literal">None</span>  <span class="hl-comment"># Target data distribution</span></span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Neural network to learn the flow</span></span>
<span class="line">        self.flow_network = nn.Sequential(</span>
<span class="line">            nn.Linear(input_dim + <span class="hl-number">1</span>, hidden_dim),  <span class="hl-comment"># +1 for time conditioning</span></span>
<span class="line">            nn.ReLU(),</span>
<span class="line">            nn.Linear(hidden_dim, hidden_dim),</span>
<span class="line">            nn.ReLU(),</span>
<span class="line">            nn.Linear(hidden_dim, input_dim)</span>
<span class="line">        )</span>
<span class="line">        </span>
<span class="line">        self.optimizer = optim.Adam(self.flow_network.parameters())</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">sample_base_distribution</span>(<span class="hl-params">self, num_samples</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Sample from the base (initial) distribution</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            num_samples (int): Number of samples to generate</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Samples from base distribution</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-comment"># Example: Gaussian distribution</span></span>
<span class="line">        <span class="hl-keyword">return</span> torch.randn(num_samples, self.input_dim)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">probability_flow_ode</span>(<span class="hl-params">self, x, t</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Compute the probability flow ODE</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            x (torch.Tensor): Current data point</span></span>
<span class="line"><span class="hl-string">            t (torch.Tensor): Time variable</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Flow direction</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-comment"># Combine input and time as network input</span></span>
<span class="line">        network_input = torch.cat([x, t], dim=<span class="hl-number">1</span>)</span>
<span class="line">        <span class="hl-keyword">return</span> self.flow_network(network_input)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">conditional_vector_field</span>(<span class="hl-params">self, x0, x1, t</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Compute the conditional vector field</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            x0 (torch.Tensor): Initial data point</span></span>
<span class="line"><span class="hl-string">            x1 (torch.Tensor): Target data point</span></span>
<span class="line"><span class="hl-string">            t (torch.Tensor): Time variable</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Conditional vector field</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-comment"># Interpolate between source and target</span></span>
<span class="line">        x_t = x0 * (<span class="hl-number">1</span> - t) + x1 * t</span>
<span class="line">        vector_field = x1 - x0</span>
<span class="line">        <span class="hl-keyword">return</span> vector_field</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">loss_function</span>(<span class="hl-params">self, x0, x1</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Compute the flow matching loss</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            x0 (torch.Tensor): Initial data points</span></span>
<span class="line"><span class="hl-string">            x1 (torch.Tensor): Target data points</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Training loss</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        batch_size = x0.shape[<span class="hl-number">0</span>]</span>
<span class="line">        t = torch.rand(batch_size, <span class="hl-number">1</span>)  <span class="hl-comment"># Random time sampling</span></span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Compute vector field</span></span>
<span class="line">        true_vector_field = self.conditional_vector_field(x0, x1, t)</span>
<span class="line">        predicted_vector_field = self.probability_flow_ode(x0, t)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Compute MSE loss between true and predicted vector fields</span></span>
<span class="line">        loss = torch.mean((predicted_vector_field - true_vector_field) ** <span class="hl-number">2</span>)</span>
<span class="line">        <span class="hl-keyword">return</span> loss</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">train</span>(<span class="hl-params">self, dataloader, epochs</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Train the Flow Matching Model</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            dataloader (torch.utils.data.DataLoader): Training data</span></span>
<span class="line"><span class="hl-string">            epochs (int): Number of training epochs</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-keyword">for</span> epoch <span class="hl-keyword">in</span> <span class="hl-built_in">range</span>(epochs):</span>
<span class="line">            <span class="hl-keyword">for</span> batch_x0, batch_x1 <span class="hl-keyword">in</span> dataloader:</span>
<span class="line">                self.optimizer.zero_grad()</span>
<span class="line">                loss = self.loss_function(batch_x0, batch_x1)</span>
<span class="line">                loss.backward()</span>
<span class="line">                self.optimizer.step()</span>
<span class="line">            </span>
<span class="line">            <span class="hl-built_in">print</span>(<span class="hl-string">f&quot;Epoch <span class="hl-subst">{epoch+<span class="hl-number">1</span>}</span>/<span class="hl-subst">{epochs}</span>, Loss: <span class="hl-subst">{loss.item()}</span>&quot;</span>)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">generate_samples</span>(<span class="hl-params">self, num_samples</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Generate new samples using the learned flow</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            num_samples (int): Number of samples to generate</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Generated samples</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-comment"># Start from base distribution and follow the learned flow</span></span>
<span class="line">        x0 = self.sample_base_distribution(num_samples)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Perform sampling through ODE solving</span></span>
<span class="line">        x_generated = x0  <span class="hl-comment"># Starting point</span></span>
<span class="line">        time_steps = torch.linspace(<span class="hl-number">0</span>, <span class="hl-number">1</span>, <span class="hl-number">100</span>)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-keyword">for</span> t <span class="hl-keyword">in</span> time_steps[<span class="hl-number">1</span>:]:</span>
<span class="line">            vector_field = self.probability_flow_ode(x_generated, t)</span>
<span class="line">            x_generated += vector_field * (time_steps[<span class="hl-number">1</span>] - time_steps[<span class="hl-number">0</span>])</span>
<span class="line">        </span>
<span class="line">        <span class="hl-keyword">return</span> x_generated</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">main</span>():</span>
<span class="line">    <span class="hl-comment"># Hyperparameters</span></span>
<span class="line">    input_dim = <span class="hl-number">10</span></span>
<span class="line">    hidden_dim = <span class="hl-number">64</span></span>
<span class="line">    num_epochs = <span class="hl-number">100</span></span>
<span class="line">    </span>
<span class="line">    flow_matching = FlowMatchingModel(input_dim, hidden_dim)</span>
<span class="line">    flow_matching.train(dataloader, num_epochs)</span>
<span class="line">    generated_samples = flow_matching.generate_samples(<span class="hl-number">1000</span>)</span></code></pre>

</figure>
</article>
    
  </main>

  <footer class="site-footer">
    <p>
      <a href="https://github.com/mbottoni/mbottoni.github.io/edit/master/content/posts/2024-12-01-flow.dj">
        <svg class="icon"><use href="/assets/icons.svg#edit"/></svg>
        Fix typo
      </a>
      <a href="/feed.xml">
        <svg class="icon"><use href="/assets/icons.svg#rss"/></svg>
        Subscribe
      </a>
      <a href="mailto:maruanbakriottoni@gmail.com">
        <svg class="icon"><use href="/assets/icons.svg#email"/></svg>
        Get in touch
      </a>
      <a href="https://github.com/mbottoni">
        <svg class="icon"><use href="/assets/icons.svg#github"/></svg>
        mbottoni
      </a>
    </p>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"></script>
  <script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true });
  </script>
  <script>
    function unwrapPlainSpans(root) {
      for (const span of root.querySelectorAll("span")) {
        if (!(span instanceof HTMLElement)) continue;
        if (span.attributes.length === 0 && span.childElementCount === 0) {
          span.replaceWith(document.createTextNode(span.textContent || ""));
        }
      }
      root.normalize();
    }

    function addCopyButtons() {
      document.querySelectorAll('figure.code-block').forEach(block => {
        if (block.querySelector('.copy-button')) return;
        const button = document.createElement('button');
        button.className = 'copy-button';
        button.textContent = 'Copy';
        button.addEventListener('click', () => {
          const code = block.querySelector('code')?.innerText || '';
          navigator.clipboard.writeText(code).then(() => {
            button.textContent = 'Copied!';
            setTimeout(() => button.textContent = 'Copy', 2000);
          });
        });
        block.appendChild(button);
      });
    }

    document.addEventListener("DOMContentLoaded", () => {
      unwrapPlainSpans(document.body);
      addCopyButtons();
      let attempts = 0;
      const maxAttempts = 40;
      const renderMath = () => {
        if (typeof renderMathInElement === "function") {
          renderMathInElement(document.body, {
            delimiters: [
              { left: "$$", right: "$$", display: true },
              { left: "$", right: "$", display: false },
              { left: "\(", right: "\)", display: false },
              { left: "\[", right: "\]", display: true },
            ],
            throwOnError: false,
          });
        } else if (attempts < maxAttempts) {
          attempts += 1;
          setTimeout(renderMath, 75);
        }
      };
      renderMath();
    });
  </script>
</body>

</html>
