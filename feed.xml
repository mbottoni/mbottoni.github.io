<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
<link href="https://mbottoni.github.io/feed.xml" rel="self" type="application/atom+xml"/>
<link href="https://mbottoni.github.io" rel="alternate" type="text/html"/>
<updated>2025-08-05T22:25:22.474Z</updated>
<id>https://mbottoni.github.io/feed.xml</id>
<title type="html">mbottoni</title>
<subtitle>Yet another programming blog by Maruan Bakri Ottoni aka mbottoni.</subtitle>
<author><name>Alex Kladov</name></author>

<entry>
<title type="text">Mixture of Experts</title>
<link href="https://mbottoni.github.io/2025/08/04/moe.html" rel="alternate" type="text/html" title="Mixture of Experts" />
<published>2025-08-04T00:00:00+00:00</published>
<updated>2025-08-04T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2025/08/04/moe</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[In the pursuit of scaling neural networks to unprecedented parameter counts while 
maintaining computational tractability, the paradigm of conditional computation 
has emerged as a cornerstone of modern deep learning architectures. A prominent and 
highly successful incarnation of this principle is the Mixture of Experts (MoE) layer. At its core, an MoE model eschews 
the monolithic, dense activation of traditional networks, wherein every parameter is engaged 
for every input. Instead, it employs a collection of specialized 
subnetworks, termed experts, and dynamically selects a sparse combination of these 
experts to process each input token. This approach allows for a dramatic increase in 
model capacity without a commensurate rise in computational cost (FLOPs), as only 
a fraction of the network's parameters are utilized for any given forward pass.]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2025/08/04/moe.html"><![CDATA[
    <h1>
    <a href="#Mixture-of-Experts"><span>Mixture of Experts</span> <time datetime="2025-08-04">Aug 4, 2025</time></a>
    </h1>
<p><span>In the pursuit of scaling neural networks to unprecedented parameter counts while </span>
<span>maintaining computational tractability, the paradigm of conditional computation </span>
<span>has emerged as a cornerstone of modern deep learning architectures. A prominent and </span>
<span>highly successful incarnation of this principle is the Mixture of Experts (MoE) layer. At its core, an MoE model eschews </span>
<span>the monolithic, dense activation of traditional networks, wherein every parameter is engaged </span>
<span>for every input. Instead, it employs a collection of specialized </span>
<span>subnetworks, termed </span>&ldquo;<span>experts,</span>&rdquo;<span> and dynamically selects a sparse combination of these </span>
<span>experts to process each input token. This approach allows for a dramatic increase in </span>
<span>model capacity without a commensurate rise in computational cost (FLOPs), as only </span>
<span>a fraction of the network</span>&rsquo;<span>s parameters are utilized for any given forward pass.</span></p>
<p><span>The architecture is orchestrated by two primary components: a set of N expert </span>
<span>networks, E</span><em><span>1, E</span></em><span>2, </span>&hellip;<span>, E_N, and a trainable gating network, G. The expert </span>
<span>networks are typically homogenous in their architecture (e.g., small feed-forward networks) but learn </span>
<span>distinct functions over the course of training. The gating network, often a simple linear layer </span>
<span>followed by a softmax function, serves as a dynamic router. For a given input vector x, the gating network produces a </span>
<span>normalized distribution of weights over the N experts, effectively learning to predict which experts </span>
<span>are most suitable for processing that specific input.</span></p>
<p><span>The final output of the MoE layer, y, is not the output of a single chosen expert but </span>
<span>rather a weighted sum of the outputs from all experts. The weights for this </span>
<span>summation are precisely the probabilities generated by the gating network. The output is thus computed as: y = \sum</span><em><span>^{N} g</span></em><span>i(x)  E_i(x)</span>
<span>where E</span><span>_i(x) is the output of the i-th expert for the input x, and g(x) is the vector of gating weights produced by the gating </span>
<span>network G. The weights are typically computed via a softmax over the logits.</span></p>
<p><span>In practice, to enforce sparsity and reduce computation, a variant known as </span>
<span>the Sparse Mixture of Experts is commonly deployed. In this formulation, only the </span>
<span>experts with the highest gating weights—the </span>&ldquo;<span>top-k</span>&rdquo;<span> experts, where $k$ is a small </span>
<span>integer (e.g., 1 or 2)—are activated. The gating weights are re-normalized over </span>
<span>this small subset of selected experts. This ensures that the computational cost is independent </span>
<span>of the total number of experts, N, and dependent only on k. This sparse, conditional activation is the key to the MoE</span>&rsquo;<span>s efficiency.</span></p>
<section id="Pseudocode-Top-k-Mixture-of-Experts-Forward-Pass">

    <h3>
    <a href="#Pseudocode-Top-k-Mixture-of-Experts-Forward-Pass"><span>Pseudocode: Top-k Mixture of Experts Forward Pass</span> </a>
    </h3>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-comment"># Let x be the input token representation</span></span>
<span class="line"><span class="hl-comment"># Let E be the set of N expert networks {E_1, ..., E_N}</span></span>
<span class="line"><span class="hl-comment"># Let G be the gating network</span></span>
<span class="line"><span class="hl-comment"># Let k be the number of experts to select</span></span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># 1. Compute gating logits for the input token x.</span></span>
<span class="line"><span class="hl-comment"># W_g is the weight matrix of the gating network.</span></span>
<span class="line">logits = G(x)  <span class="hl-comment"># Shape: [N]</span></span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># 2. Select the top k experts.</span></span>
<span class="line"><span class="hl-comment"># Get the k largest logit values and their corresponding indices.</span></span>
<span class="line">top_k_logits, top_k_indices = TopK(logits, k)</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># 3. Compute the normalized routing weights for the selected experts.</span></span>
<span class="line"><span class="hl-comment"># Apply softmax only to the selected logits to get sparse weights.</span></span>
<span class="line">routing_weights = Softmax(top_k_logits) <span class="hl-comment"># Shape: [k]</span></span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># 4. Initialize the final output vector.</span></span>
<span class="line"><span class="hl-comment"># The output has the same dimension as the expert outputs.</span></span>
<span class="line">final_output = <span class="hl-number">0</span></span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># 5. Compute the weighted sum of the selected expert outputs.</span></span>
<span class="line"><span class="hl-comment"># Iterate through the chosen experts and their corresponding weights.</span></span>
<span class="line"><span class="hl-keyword">for</span> i <span class="hl-keyword">in</span> <span class="hl-number">1.</span>.k:</span>
<span class="line">    <span class="hl-comment"># Get the index of the i-th expert in the top-k set.</span></span>
<span class="line">    expert_index = top_k_indices[i]</span>
<span class="line"></span>
<span class="line">    <span class="hl-comment"># Get the routing weight for this expert.</span></span>
<span class="line">    weight = routing_weights[i]</span>
<span class="line"></span>
<span class="line">    <span class="hl-comment"># Retrieve the corresponding expert network.</span></span>
<span class="line">    selected_expert = E[expert_index]</span>
<span class="line"></span>
<span class="line">    <span class="hl-comment"># Process the input token with the selected expert.</span></span>
<span class="line">    expert_output = selected_expert(x)</span>
<span class="line"></span>
<span class="line">    <span class="hl-comment"># Accumulate the weighted expert output.</span></span>
<span class="line">    final_output += weight * expert_output</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># 6. Return the combined output.</span></span>
<span class="line"><span class="hl-comment"># This output is then passed to the next layer in the network.</span></span>
<span class="line"><span class="hl-keyword">return</span> final_output</span></code></pre>

</figure>
</section>
]]></content>
</entry>

<entry>
<title type="text">What is Neural Collapse? A Simpler Look</title>
<link href="https://mbottoni.github.io/2025/07/08/neural-collapse.html" rel="alternate" type="text/html" title="What is Neural Collapse? A Simpler Look" />
<published>2025-07-08T00:00:00+00:00</published>
<updated>2025-07-08T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2025/07/08/neural-collapse</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[Imagine you're training a very powerful neural network to recognize different classes of images, like 
cats, dogs, and cars. In the beginning, the network struggles, but eventually, it gets 
a perfect score on your training data.]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2025/07/08/neural-collapse.html"><![CDATA[
    <h1>
    <a href="#What-is-Neural-Collapse-A-Simpler-Look"><span>What is Neural Collapse? A Simpler Look</span> <time datetime="2025-07-08">Jul 8, 2025</time></a>
    </h1>
<p><span>Imagine you</span>&rsquo;<span>re training a very powerful neural network to recognize different classes of images, like </span>
<span>cats, dogs, and cars. In the beginning, the network struggles, but eventually, it gets </span>
<span>a perfect score on your training data.</span></p>
<p><span>You might think that if you keep training it on the same data, it would </span>
<span>either stop learning or get confused and </span>&ldquo;<span>overthink</span>&rdquo;<span> the problem. But </span>
<span>something remarkable and unexpected happens instead: the network</span>&rsquo;<span>s internal </span>
<span>organization becomes incredibly simple and tidy. This process of self-organization </span>
<span>into a perfect, simple structure is called Neural Collapse.</span></p>
<p><span>It</span>&rsquo;<span>s driven by the network</span>&rsquo;<span>s hidden preference to find the </span>
<span>most efficient and straightforward solution possible, even after it has already solved the main problem.</span>
<span>Neural Collapse can be broken down into four distinct things that happen at the same time during the final stages of training.</span></p>
<ol>
<li>
<span>All Examples of a Class Become One (Variability Collapse)</span>
</li>
</ol>
<p><span>The network learns to ignore the unique details of individual images within the same class.</span></p>
<p><span>Example: Instead of creating slightly different internal </span>&ldquo;<span>codes</span>&rdquo;<span> for a fluffy Persian cat, a sleek Siamese </span>
<span>cat, and a tabby cat, the network starts producing the exact same internal code for all of them. It effectively creates a single, perfect, </span>&ldquo;<span>ultimate cat</span>&rdquo;<span> representation and throws away all the variation.</span></p>
<ol start="2">
<li>
<span>Class Codes Spread Out Perfectly (The Symmetrical Shape)</span>
</li>
</ol>
<p><span>Once the network has a single </span>&ldquo;<span>code</span>&rdquo;<span> for each class (like </span>&ldquo;<span>ultimate cat,</span>&rdquo;<span> </span>&ldquo;<span>ultimate dog,</span>&rdquo;<span> and </span>&ldquo;<span>ultimate car</span>&rdquo;<span>), it arranges these codes in the most spread-out way possible.</span></p>
<p><span>Example: If you have three classes, their codes will form the points of a </span>
<span>perfect equilateral triangle in the network</span>&rsquo;<span>s internal space. If you have four classes, they form a tetrahedron. This is the most symmetrical and separated arrangement possible, making the classes maximally distinct from one another. This perfect geometric structure is called a Simplex ETF.</span></p>
<ol start="3">
<li>
<span>The Decision-Maker Aligns Perfectly (Self-Duality)</span>
</li>
</ol>
<p><span>The final part of the network that makes the decision (the </span>&ldquo;<span>classifier</span>&rdquo;<span>) also simplifies. The classifier</span>&rsquo;<span>s internal </span>
<span>template for </span>&ldquo;<span>cat</span>&rdquo;<span> perfectly lines up with the network</span>&rsquo;<span>s </span>&ldquo;<span>ultimate cat</span>&rdquo;<span> code. The decision-maker becomes a perfect mirror of the data</span>&rsquo;<span>s new, simple structure.</span></p>
<ol start="4">
<li>
<span>The Whole System Becomes a Simple </span>&ldquo;<span>Nearest-Neighbor</span>&rdquo;<span> Game</span>
</li>
</ol>
<p><span>Because of the three changes above, the network</span>&rsquo;<span>s complex decision-making process becomes incredibly simple. To classify a new image:</span></p>
<p><span>Example: The network creates a code for the new image. Then, it just checks which of its </span>&ldquo;<span>ultimate</span>&rdquo;<span> class </span>
<span>codes (the points of the triangle or tetrahedron) is the closest. If the </span>&ldquo;<span>ultimate cat</span>&rdquo;<span> code is the nearest neighbor, it classifies the image as a cat. The sophisticated deep network ends up behaving like a much simpler classifier.</span></p>
<p><span>To help people see this, researchers created animations showing the process. Imagine little blue balls (individual images) clustering together into a single </span>
<span>point for each class. These points (class means) then move to form a perfect symmetrical shape (the green target points), and the </span>
<span>decision-maker (red lines) aligns with them perfectly. This drive towards simplicity has important consequences.</span></p>
<ul>
<li>
<p><span>The Good: The super-organized structure makes the network very good at its main job and very good at identifying things </span>
<span>that are completely different from what it was trained on. The neat, tight clusters make it easy to spot an outsider.</span></p>
</li>
<li>
<p><span>The Trade-Off (The Bad): This simplicity comes at a cost. By erasing all the subtle details within a </span>
<span>class, the network can hurt its ability to learn new, related things later.</span></p>
</li>
</ul>
]]></content>
</entry>

<entry>
<title type="text">Swarm Structure Simulation</title>
<link href="https://mbottoni.github.io/2025/06/06/swarm.html" rel="alternate" type="text/html" title="Swarm Structure Simulation" />
<published>2025-06-06T00:00:00+00:00</published>
<updated>2025-06-06T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2025/06/06/swarm</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[After reading the book The Rules of the Flock I got inspired to test some 
ideas of the book. Basically a swarm behavior is defined when individual agents, following 
a simple set of local rules without a central leader, produce complex and 
intelligent collective patterns.]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2025/06/06/swarm.html"><![CDATA[
    <h1>
    <a href="#Swarm-Structure-Simulation"><span>Swarm Structure Simulation</span> <time datetime="2025-06-06">Jun 6, 2025</time></a>
    </h1>
<p><span>After reading the book The Rules of the Flock I got inspired to test some </span>
<span>ideas of the book. Basically a swarm behavior is defined when individual agents, following </span>
<span>a simple set of local rules without a central leader, produce complex and </span>
<span>intelligent collective patterns.</span></p>
<p><span>To see these rules in action, I developed the interactive Python simulation </span>
<span>detailed below. Using Matplotlib, the simulation visualizes a </span>
<span>flock of </span>&lsquo;<span>boids</span>&rsquo;<span>. You can use the sliders to change the weight of </span>
<span>each rule in real-time—crank up </span>&lsquo;<span>Cohesion</span>&rsquo;<span> to see the flock tighten, or increase </span>
&lsquo;<span>Separation</span>&rsquo;<span> to watch them spread out. You can also interact directly </span>
<span>with the swarm using your mouse, acting as a predator to </span>
<span>scatter the flock or a point of interest to draw them in. It</span>&rsquo;<span>s a fascinating look </span>
<span>at how complex, life-like motion can emerge from a few simple, local instructions.</span></p>

<figure class="code-block">


<pre><code><span class="line"></span>
<span class="line"><span class="hl-keyword">import</span> numpy <span class="hl-keyword">as</span> np</span>
<span class="line"><span class="hl-keyword">import</span> matplotlib.pyplot <span class="hl-keyword">as</span> plt</span>
<span class="line"><span class="hl-keyword">import</span> matplotlib.animation <span class="hl-keyword">as</span> animation</span>
<span class="line"><span class="hl-keyword">from</span> matplotlib.widgets <span class="hl-keyword">import</span> Slider</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># --- Simulation Configuration ---</span></span>
<span class="line">N_BOIDS = <span class="hl-number">150</span></span>
<span class="line">WIDTH, HEIGHT = <span class="hl-number">1200</span>, <span class="hl-number">800</span></span>
<span class="line">PERCEPTION_RADIUS = <span class="hl-number">70</span></span>
<span class="line">MAX_SPEED = <span class="hl-number">5.0</span></span>
<span class="line">MIN_SPEED = <span class="hl-number">2.0</span></span>
<span class="line">MOUSE_INFLUENCE_RADIUS = <span class="hl-number">150.0</span></span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># --- Weights for the rules ---</span></span>
<span class="line">INITIAL_SEPARATION_WEIGHT = <span class="hl-number">1.5</span></span>
<span class="line">INITIAL_ALIGNMENT_WEIGHT = <span class="hl-number">1.0</span></span>
<span class="line">INITIAL_COHESION_WEIGHT = <span class="hl-number">1.0</span></span>
<span class="line">MOUSE_ATTRACT_WEIGHT = <span class="hl-number">2.5</span></span>
<span class="line">MOUSE_REPEL_WEIGHT = <span class="hl-number">3.0</span></span>
<span class="line">INITIAL_COND = <span class="hl-string">&#x27;random&#x27;</span> <span class="hl-comment"># circle, random, grid</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">class</span> <span class="hl-title class_">Boids</span>:</span>
<span class="line">    <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">    A class to manage the state and behavior of a flock of boids.</span></span>
<span class="line"><span class="hl-string">    &quot;&quot;&quot;</span></span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">__init__</span>(<span class="hl-params">self, count, width, height, initial_condition=<span class="hl-string">&#x27;random&#x27;</span></span>):</span>
<span class="line">        self.width = width</span>
<span class="line">        self.height = height</span>
<span class="line">        self.count = count</span>
<span class="line"></span>
<span class="line">        self.positions, self.velocities = self._initialize_boids(initial_condition)</span>
<span class="line"></span>
<span class="line">        self.weights = {</span>
<span class="line">            <span class="hl-string">&#x27;separation&#x27;</span>: INITIAL_SEPARATION_WEIGHT,</span>
<span class="line">            <span class="hl-string">&#x27;alignment&#x27;</span>: INITIAL_ALIGNMENT_WEIGHT,</span>
<span class="line">            <span class="hl-string">&#x27;cohesion&#x27;</span>: INITIAL_COHESION_WEIGHT</span>
<span class="line">        }</span>
<span class="line"></span>
<span class="line">        self.mouse_pos = <span class="hl-literal">None</span></span>
<span class="line">        self.mouse_mode = <span class="hl-literal">None</span> <span class="hl-comment"># &#x27;attract&#x27; or &#x27;repel&#x27;</span></span>
<span class="line"></span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">_initialize_boids</span>(<span class="hl-params">self, condition</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;Sets the initial positions and velocities of the boids.&quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-keyword">if</span> condition == <span class="hl-string">&#x27;circle&#x27;</span>:</span>
<span class="line">            center = np.array([self.width / <span class="hl-number">2</span>, self.height / <span class="hl-number">2</span>])</span>
<span class="line">            radius = <span class="hl-built_in">min</span>(self.width, self.height) / <span class="hl-number">4</span></span>
<span class="line">            angles = np.linspace(<span class="hl-number">0</span>, <span class="hl-number">2</span> * np.pi, self.count)</span>
<span class="line">            positions = center + radius * np.c_[np.cos(angles), np.sin(angles)]</span>
<span class="line">            velocities = (np.c_[-np.sin(angles), np.cos(angles)]) * MIN_SPEED</span>
<span class="line">        <span class="hl-keyword">elif</span> condition == <span class="hl-string">&#x27;grid&#x27;</span>:</span>
<span class="line">            grid_size = <span class="hl-built_in">int</span>(np.ceil(np.sqrt(self.count)))</span>
<span class="line">            x = np.linspace(self.width/<span class="hl-number">4</span>, <span class="hl-number">3</span>*self.width/<span class="hl-number">4</span>, grid_size)</span>
<span class="line">            y = np.linspace(self.height/<span class="hl-number">4</span>, <span class="hl-number">3</span>*self.height/<span class="hl-number">4</span>, grid_size)</span>
<span class="line">            xx, yy = np.meshgrid(x, y)</span>
<span class="line">            positions = np.c_[xx.ravel(), yy.ravel()][:self.count]</span>
<span class="line">            velocities = np.full((self.count, <span class="hl-number">2</span>), [<span class="hl-number">0</span>, -MIN_SPEED])</span>
<span class="line">        <span class="hl-keyword">else</span>: <span class="hl-comment"># &#x27;random&#x27;</span></span>
<span class="line">            positions = np.random.rand(self.count, <span class="hl-number">2</span>) * np.array([self.width, self.height])</span>
<span class="line">            velocities = (np.random.rand(self.count, <span class="hl-number">2</span>) - <span class="hl-number">0.5</span>) * MAX_SPEED</span>
<span class="line"></span>
<span class="line">        <span class="hl-keyword">return</span> positions, velocities</span>
<span class="line"></span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">_apply_rules</span>(<span class="hl-params">self</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;Applies boid rules to calculate acceleration.&quot;&quot;&quot;</span></span>
<span class="line">        deltas = self.positions[:, np.newaxis, :] - self.positions[np.newaxis, :, :]</span>
<span class="line">        distances = np.sqrt(np.<span class="hl-built_in">sum</span>(deltas**<span class="hl-number">2</span>, axis=<span class="hl-number">2</span>))</span>
<span class="line"></span>
<span class="line">        separation_vec = np.zeros_like(self.positions)</span>
<span class="line">        alignment_vec = np.zeros_like(self.positions)</span>
<span class="line">        cohesion_vec = np.zeros_like(self.positions)</span>
<span class="line"></span>
<span class="line">        neighbor_mask = (distances &gt; <span class="hl-number">0</span>) &amp; (distances &lt; PERCEPTION_RADIUS)</span>
<span class="line"></span>
<span class="line">        <span class="hl-keyword">for</span> i <span class="hl-keyword">in</span> <span class="hl-built_in">range</span>(self.count):</span>
<span class="line">            neighbors = neighbor_mask[i]</span>
<span class="line">            <span class="hl-keyword">if</span> <span class="hl-keyword">not</span> np.<span class="hl-built_in">any</span>(neighbors):</span>
<span class="line">                <span class="hl-keyword">continue</span></span>
<span class="line"></span>
<span class="line">            close_mask = (distances[i] &gt; <span class="hl-number">0</span>) &amp; (distances[i] &lt; PERCEPTION_RADIUS / <span class="hl-number">2</span>)</span>
<span class="line">            <span class="hl-keyword">if</span> np.<span class="hl-built_in">any</span>(close_mask):</span>
<span class="line">                avg_pos_close = np.mean(self.positions[close_mask], axis=<span class="hl-number">0</span>)</span>
<span class="line">                separation_vec[i] = self.positions[i] - avg_pos_close</span>
<span class="line"></span>
<span class="line">            alignment_vec[i] = np.mean(self.velocities[neighbors], axis=<span class="hl-number">0</span>)</span>
<span class="line"></span>
<span class="line">            avg_pos_all = np.mean(self.positions[neighbors], axis=<span class="hl-number">0</span>)</span>
<span class="line">            cohesion_vec[i] = avg_pos_all - self.positions[i]</span>
<span class="line"></span>
<span class="line">        <span class="hl-keyword">for</span> vec <span class="hl-keyword">in</span> [separation_vec, alignment_vec, cohesion_vec]:</span>
<span class="line">            norm = np.sqrt(np.<span class="hl-built_in">sum</span>(vec**<span class="hl-number">2</span>, axis=<span class="hl-number">1</span>))[:, np.newaxis]</span>
<span class="line">            non_zero_mask = norm.flatten() &gt; <span class="hl-number">0</span></span>
<span class="line">            <span class="hl-keyword">if</span> np.<span class="hl-built_in">any</span>(non_zero_mask):</span>
<span class="line">                vec[non_zero_mask] /= norm[non_zero_mask]</span>
<span class="line"></span>
<span class="line">        mouse_steer = np.zeros_like(self.positions)</span>
<span class="line">        <span class="hl-keyword">if</span> self.mouse_pos <span class="hl-keyword">is</span> <span class="hl-keyword">not</span> <span class="hl-literal">None</span>:</span>
<span class="line">            mouse_delta = self.mouse_pos - self.positions</span>
<span class="line">            mouse_dist = np.sqrt(np.<span class="hl-built_in">sum</span>(mouse_delta**<span class="hl-number">2</span>, axis=<span class="hl-number">1</span>))</span>
<span class="line">            influence_mask = mouse_dist &lt; MOUSE_INFLUENCE_RADIUS</span>
<span class="line"></span>
<span class="line">            <span class="hl-keyword">if</span> self.mouse_mode == <span class="hl-string">&#x27;attract&#x27;</span>:</span>
<span class="line">                mouse_steer[influence_mask] = mouse_delta[influence_mask] * MOUSE_ATTRACT_WEIGHT</span>
<span class="line">            <span class="hl-keyword">elif</span> self.mouse_mode == <span class="hl-string">&#x27;repel&#x27;</span>:</span>
<span class="line">                repel_force = (MOUSE_INFLUENCE_RADIUS - mouse_dist[influence_mask, np.newaxis]) / MOUSE_INFLUENCE_RADIUS</span>
<span class="line">                mouse_steer[influence_mask] = -mouse_delta[influence_mask] * MOUSE_REPEL_WEIGHT * repel_force</span>
<span class="line"></span>
<span class="line">        acceleration = (separation_vec * self.weights[<span class="hl-string">&#x27;separation&#x27;</span>] +</span>
<span class="line">                        alignment_vec * self.weights[<span class="hl-string">&#x27;alignment&#x27;</span>] +</span>
<span class="line">                        cohesion_vec * self.weights[<span class="hl-string">&#x27;cohesion&#x27;</span>] +</span>
<span class="line">                        mouse_steer)</span>
<span class="line">        <span class="hl-keyword">return</span> acceleration</span>
<span class="line"></span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">update</span>(<span class="hl-params">self</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;Updates the position and velocity of each boid.&quot;&quot;&quot;</span></span>
<span class="line">        acceleration = self._apply_rules()</span>
<span class="line">        self.velocities += acceleration</span>
<span class="line"></span>
<span class="line">        speeds = np.sqrt(np.<span class="hl-built_in">sum</span>(self.velocities**<span class="hl-number">2</span>, axis=<span class="hl-number">1</span>))</span>
<span class="line">        speed_mask_max = speeds &gt; MAX_SPEED</span>
<span class="line">        speed_mask_min = speeds &lt; MIN_SPEED</span>
<span class="line"></span>
<span class="line">        <span class="hl-keyword">if</span> np.<span class="hl-built_in">any</span>(speed_mask_max):</span>
<span class="line">             self.velocities[speed_mask_max] *= (MAX_SPEED / speeds[speed_mask_max, np.newaxis])</span>
<span class="line">        <span class="hl-keyword">if</span> np.<span class="hl-built_in">any</span>(speed_mask_min):</span>
<span class="line">             self.velocities[speed_mask_min] *= (MIN_SPEED / speeds[speed_mask_min, np.newaxis])</span>
<span class="line"></span>
<span class="line">        self.positions += self.velocities</span>
<span class="line"></span>
<span class="line">        self.positions[:, <span class="hl-number">0</span>] = np.mod(self.positions[:, <span class="hl-number">0</span>], self.width)</span>
<span class="line">        self.positions[:, <span class="hl-number">1</span>] = np.mod(self.positions[:, <span class="hl-number">1</span>], self.height)</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># --- Visualization and Interactivity ---</span></span>
<span class="line"></span>
<span class="line">boids = Boids(N_BOIDS, WIDTH, HEIGHT, initial_condition=INITIAL_COND)</span>
<span class="line"></span>
<span class="line">fig, ax = plt.subplots(figsize=(<span class="hl-number">12</span>, <span class="hl-number">9</span>))</span>
<span class="line"><span class="hl-comment"># Leave space at the bottom for sliders and description text</span></span>
<span class="line">plt.subplots_adjust(bottom=<span class="hl-number">0.3</span>, left=<span class="hl-number">0.1</span>)</span>
<span class="line">ax.set_xlim(<span class="hl-number">0</span>, WIDTH)</span>
<span class="line">ax.set_ylim(<span class="hl-number">0</span>, HEIGHT)</span>
<span class="line">ax.set_xticks([])</span>
<span class="line">ax.set_yticks([])</span>
<span class="line">ax.set_facecolor(<span class="hl-string">&#x27;k&#x27;</span>)</span>
<span class="line">fig.set_facecolor(<span class="hl-string">&#x27;k&#x27;</span>)</span>
<span class="line"></span>
<span class="line">quiver = ax.quiver(boids.positions[:, <span class="hl-number">0</span>], boids.positions[:, <span class="hl-number">1</span>],</span>
<span class="line">                   boids.velocities[:, <span class="hl-number">0</span>], boids.velocities[:, <span class="hl-number">1</span>],</span>
<span class="line">                   color=<span class="hl-string">&#x27;cyan&#x27;</span>, headwidth=<span class="hl-number">2</span>, headlength=<span class="hl-number">3</span>)</span>
<span class="line"></span>
<span class="line">mode_text = ax.text(<span class="hl-number">10</span>, HEIGHT - <span class="hl-number">20</span>, <span class="hl-string">&quot;Mode: Normal&quot;</span>, color=<span class="hl-string">&#x27;white&#x27;</span>, fontsize=<span class="hl-number">12</span>)</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># --- Mouse Click Event Handler ---</span></span>
<span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">on_click</span>(<span class="hl-params">event</span>):</span>
<span class="line">    <span class="hl-keyword">if</span> event.inaxes:</span>
<span class="line">        boids.mouse_pos = np.array([event.xdata, event.ydata])</span>
<span class="line">        <span class="hl-keyword">if</span> event.button == <span class="hl-number">1</span>:</span>
<span class="line">            boids.mouse_mode = <span class="hl-string">&#x27;attract&#x27;</span></span>
<span class="line">            mode_text.set_text(<span class="hl-string">&quot;Mode: Attract (Left-Click)&quot;</span>)</span>
<span class="line">        <span class="hl-keyword">elif</span> event.button == <span class="hl-number">3</span>:</span>
<span class="line">            boids.mouse_mode = <span class="hl-string">&#x27;repel&#x27;</span></span>
<span class="line">            mode_text.set_text(<span class="hl-string">&quot;Mode: Repel (Right-Click)&quot;</span>)</span>
<span class="line">        <span class="hl-keyword">elif</span> event.button == <span class="hl-number">2</span>:</span>
<span class="line">            boids.mouse_mode = <span class="hl-literal">None</span></span>
<span class="line">            boids.mouse_pos = <span class="hl-literal">None</span></span>
<span class="line">            mode_text.set_text(<span class="hl-string">&quot;Mode: Normal (Middle-Click)&quot;</span>)</span>
<span class="line">fig.canvas.mpl_connect(<span class="hl-string">&#x27;button_press_event&#x27;</span>, on_click)</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># --- Sliders and Description Text ---</span></span>
<span class="line">ax_sep = plt.axes([<span class="hl-number">0.25</span>, <span class="hl-number">0.18</span>, <span class="hl-number">0.65</span>, <span class="hl-number">0.03</span>])</span>
<span class="line">ax_ali = plt.axes([<span class="hl-number">0.25</span>, <span class="hl-number">0.13</span>, <span class="hl-number">0.65</span>, <span class="hl-number">0.03</span>])</span>
<span class="line">ax_coh = plt.axes([<span class="hl-number">0.25</span>, <span class="hl-number">0.08</span>, <span class="hl-number">0.65</span>, <span class="hl-number">0.03</span>])</span>
<span class="line"></span>
<span class="line">slider_sep = Slider(ax_sep, <span class="hl-string">&#x27;Separation&#x27;</span>, <span class="hl-number">0.1</span>, <span class="hl-number">5.0</span>, valinit=INITIAL_SEPARATION_WEIGHT, color=<span class="hl-string">&#x27;c&#x27;</span>)</span>
<span class="line">slider_ali = Slider(ax_ali, <span class="hl-string">&#x27;Alignment&#x27;</span>, <span class="hl-number">0.1</span>, <span class="hl-number">5.0</span>, valinit=INITIAL_ALIGNMENT_WEIGHT, color=<span class="hl-string">&#x27;c&#x27;</span>)</span>
<span class="line">slider_coh = Slider(ax_coh, <span class="hl-string">&#x27;Cohesion&#x27;</span>, <span class="hl-number">0.1</span>, <span class="hl-number">5.0</span>, valinit=INITIAL_COHESION_WEIGHT, color=<span class="hl-string">&#x27;c&#x27;</span>)</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># Add the text area for descriptions</span></span>
<span class="line">description_text = fig.text(</span>
<span class="line">    <span class="hl-number">0.5</span>, <span class="hl-number">0.02</span>,</span>
<span class="line">    <span class="hl-string">&quot;Move a slider to see its description.&quot;</span>,</span>
<span class="line">    color=<span class="hl-string">&#x27;yellow&#x27;</span>, ha=<span class="hl-string">&#x27;center&#x27;</span>, va=<span class="hl-string">&#x27;bottom&#x27;</span>, fontsize=<span class="hl-number">10</span></span>
<span class="line">)</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># Descriptions for each slider</span></span>
<span class="line">descriptions = {</span>
<span class="line">    <span class="hl-string">&#x27;separation&#x27;</span>: <span class="hl-string">&quot;Separation: Controls how strongly boids steer to avoid crowding neighbors. Higher values prevent collisions.&quot;</span>,</span>
<span class="line">    <span class="hl-string">&#x27;alignment&#x27;</span>: <span class="hl-string">&quot;Alignment: Controls how strongly boids steer to match the heading of their neighbors. Higher values create more parallel flight.&quot;</span>,</span>
<span class="line">    <span class="hl-string">&#x27;cohesion&#x27;</span>: <span class="hl-string">&quot;Cohesion: Controls how strongly boids steer towards the center of their neighbors. Higher values create tighter flocks.&quot;</span></span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># Functions to update weights AND the description text</span></span>
<span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">update_separation</span>(<span class="hl-params">val</span>):</span>
<span class="line">    boids.weights[<span class="hl-string">&#x27;separation&#x27;</span>] = val</span>
<span class="line">    description_text.set_text(descriptions[<span class="hl-string">&#x27;separation&#x27;</span>])</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">update_alignment</span>(<span class="hl-params">val</span>):</span>
<span class="line">    boids.weights[<span class="hl-string">&#x27;alignment&#x27;</span>] = val</span>
<span class="line">    description_text.set_text(descriptions[<span class="hl-string">&#x27;alignment&#x27;</span>])</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">update_cohesion</span>(<span class="hl-params">val</span>):</span>
<span class="line">    boids.weights[<span class="hl-string">&#x27;cohesion&#x27;</span>] = val</span>
<span class="line">    description_text.set_text(descriptions[<span class="hl-string">&#x27;cohesion&#x27;</span>])</span>
<span class="line"></span>
<span class="line">slider_sep.on_changed(update_separation)</span>
<span class="line">slider_ali.on_changed(update_alignment)</span>
<span class="line">slider_coh.on_changed(update_cohesion)</span>
<span class="line"></span>
<span class="line"><span class="hl-comment"># --- Animation Loop ---</span></span>
<span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">animate</span>(<span class="hl-params">frame</span>):</span>
<span class="line">    boids.update()</span>
<span class="line"></span>
<span class="line">    quiver.set_offsets(boids.positions)</span>
<span class="line">    quiver.set_UVC(boids.velocities[:, <span class="hl-number">0</span>], boids.velocities[:, <span class="hl-number">1</span>])</span>
<span class="line"></span>
<span class="line">    ax.set_title(<span class="hl-string">f&quot;Interactive Swarm Simulation&quot;</span>, color=<span class="hl-string">&#x27;white&#x27;</span>)</span>
<span class="line">    <span class="hl-keyword">return</span> quiver, mode_text, description_text</span>
<span class="line"></span>
<span class="line">ani = animation.FuncAnimation(fig, animate, frames=<span class="hl-number">200</span>, interval=<span class="hl-number">30</span>, blit=<span class="hl-literal">False</span>)</span>
<span class="line"></span>
<span class="line">plt.show()</span></code></pre>

</figure>
]]></content>
</entry>

<entry>
<title type="text">Mechanistic Interpretability - Some concepts</title>
<link href="https://mbottoni.github.io/2025/04/12/mech-inter.html" rel="alternate" type="text/html" title="Mechanistic Interpretability - Some concepts" />
<published>2025-04-12T00:00:00+00:00</published>
<updated>2025-04-12T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2025/04/12/mech-inter</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[Here are some quick notes on concepts in Mechanistic Interpretability. The subject is vast and very recent and 
try to interpret features for neural networks, specifically transformers and LLM's.]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2025/04/12/mech-inter.html"><![CDATA[
    <h1>
    <a href="#Mechanistic-Interpretability-Some-concepts"><span>Mechanistic Interpretability - Some concepts</span> <time datetime="2025-04-12">Apr 12, 2025</time></a>
    </h1>
<p><span>Here are some quick notes on concepts in Mechanistic Interpretability. The subject is vast and very recent and </span>
<span>try to interpret features for neural networks, specifically transformers and LLM</span>&rsquo;<span>s.</span></p>
<p><span>This was based on my studies and mainly on this blog post </span><a href="https://www.neelnanda.io/mechanistic-interpretability/glossary"><span>Link to blog</span></a><span>. On the future when I advanced</span>
<span>my studies on this subject I will update this post.</span></p>
<ul>
<li>
<p><span>Interpretability: The broader AI subfield focused on understanding why AI systems behave as they do and translating this into human-understandable explanations.</span></p>
</li>
<li>
<p><span>Feature: A property of the model</span>&rsquo;<span>s input or a part of it. Features are fundamental; the model</span>&rsquo;<span>s internal activations represent them, and computations (weights, non-linearities) transform earlier features into later ones.</span></p>
</li>
<li>
<p><span>Circuit: A specific part of the model that performs an understandable computation, transforming interpretable input features into interpretable output features.</span></p>
</li>
<li>
<p><span>Intervening on or editing an activation: The process of running the model up to a certain point, modifying a specific activation value, and then letting the model continue its computation with the changed value.</span></p>
</li>
<li>
<p><span>Pruning a neuron: A specific intervention where a neuron</span>&rsquo;<span>s activation is set to zero, preventing subsequent layers from using its output.</span></p>
</li>
<li>
<p><span>Equivariance / Neuron families: Groups of neurons or features that are distinct but operate analogously. Understanding one member of the family helps understand the others.</span></p>
</li>
<li>
<p><span>Neuron splitting: When a single feature represented in a smaller model gets broken down into multiple distinct features in a larger model.</span></p>
</li>
<li>
<p><span>Universality: The hypothesis that the same functional circuits will emerge and be discoverable across different models trained independently.</span></p>
</li>
<li>
<p><span>Motif: An abstract computational pattern or structure that recurs across different circuits or features in various models or contexts.</span></p>
</li>
<li>
<p><span>Localised/sparse model behaviour: When a model</span>&rsquo;<span>s specific behavior is determined by only a small number of its components.</span></p>
</li>
<li>
<p><span>Microscope AI: The idea that by reverse engineering a highly capable (potentially superhuman) AI, we could learn the novel knowledge and understanding of the world that the AI has acquired.</span></p>
</li>
<li>
<p><span>The curse of dimensionality: A concept highlighting the counter-intuitive properties and complexities that arise when dealing with high-dimensional spaces, like the activation spaces within neural networks.</span></p>
</li>
<li>
<p><span>Features as directions: A key hypothesis in MI suggesting that features within a model are represented as specific directions within the high-dimensional activation vector space.</span></p>
</li>
<li>
<p><span>Few-shot learning: A capability where a generative model learns to perform a new task based on just a few examples provided within its input prompt.</span></p>
</li>
<li>
<p><span>In-Context Learning: The ability of a model to use information from much earlier in its input sequence (context) to make predictions about the next token.</span></p>
</li>
<li>
<p><span>Indirect Object Identification (IOI): A specific linguistic task used to test language models, requiring the model to identify the indirect object in sentences like </span>&ldquo;<span>When John and Mary went to the store, John gave the bag to [Mary]</span>&rdquo;<span>.</span></p>
</li>
<li>
<p><span>IOI Circuit: The specific network of components identified within the GPT-2 Small model that is responsible for correctly performing the IOI task.</span></p>
</li>
</ul>
]]></content>
</entry>

<entry>
<title type="text">Group Relative Policy Optimization (GRPO)</title>
<link href="https://mbottoni.github.io/2025/02/06/grpo.html" rel="alternate" type="text/html" title="Group Relative Policy Optimization (GRPO)" />
<published>2025-02-06T00:00:00+00:00</published>
<updated>2025-02-06T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2025/02/06/grpo</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[PPO is a reinforcement learning algorithm originally designed to update policies in a stable and reliable way.
In the context of LLM fine-tuning, the model (the “policy”) is trained using feedback from a reward model that represents human preferences.
Value Function (Critic): Estimates the “goodness” of a state, used with Generalized Advantage Estimation (GAE) to balance bias and variance.
Basically it works as follows:]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2025/02/06/grpo.html"><![CDATA[
    <h1>
    <a href="#GRPO-on-DeepSeek-r1"><span>GRPO on DeepSeek-r1</span> <time datetime="2025-02-06">Feb 6, 2025</time></a>
    </h1>

<figure>

<img alt="" src="/assets/grpo.webp">
</figure>

    <h1>
    <a href="#Proximal-Policy-Optimization-PPO"><span>Proximal Policy Optimization (PPO)</span> <time datetime="2025-02-06">Feb 6, 2025</time></a>
    </h1>
<p><span>PPO is a reinforcement learning algorithm originally designed to update policies in a stable and reliable way.</span>
<span>In the context of LLM fine-tuning, the model (the “policy”) is trained using feedback from a reward model that represents human preferences.</span>
<span>Value Function (Critic): Estimates the “goodness” of a state, used with Generalized Advantage Estimation (GAE) to balance bias and variance.</span>
<span>Basically it works as follows:</span></p>
<ol>
<li>
<span>Generate Rollouts: The LLM produces a set of text responses (rollouts) for a given prompt.</span>
</li>
<li>
<span>Score with the Reward Model: Each response is scored.</span>
</li>
<li>
<span>Compute Advantages: Using GAE, the algorithm computes how much better (or worse) each action (e.g., token choice) was compared to a baseline.</span>
</li>
<li>
<span>Update the Policy: A PPO objective is used with a clipped surrogate loss to ensure updates are not too drastic. Additional terms (like a KL penalty and entropy bonus) help maintain stability and encourage exploration.</span>
</li>
</ol>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">ppo_loss_with_gae_entropy</span>(<span class="hl-params">old_policy_logprobs, new_policy_logprobs, advantages,</span></span>
<span class="line"><span class="hl-params">                              kl_penalty_coef, clip_epsilon, entropy_bonus_coef</span>):</span>
<span class="line">    <span class="hl-comment"># Compute probability ratio between new and old policy actions</span></span>
<span class="line">    ratio = np.exp(new_policy_logprobs - old_policy_logprobs)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># Clipped surrogate objective prevents large policy updates</span></span>
<span class="line">    surrogate_objective = np.minimum(ratio * advantages,</span>
<span class="line">                                     np.clip(ratio, <span class="hl-number">1</span> - clip_epsilon, <span class="hl-number">1</span> + clip_epsilon) * advantages)</span>
<span class="line">    policy_loss = -np.mean(surrogate_objective)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># KL divergence penalty to keep new policy close to the old one</span></span>
<span class="line">    kl_divergence = np.mean(new_policy_logprobs - old_policy_logprobs)</span>
<span class="line">    kl_penalty = kl_penalty_coef * kl_divergence</span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># Entropy bonus encourages exploration (i.e., less certainty)</span></span>
<span class="line">    entropy = -np.mean(new_policy_logprobs)</span>
<span class="line">    entropy_bonus = entropy_bonus_coef * entropy</span>
<span class="line">    </span>
<span class="line">    total_loss = policy_loss + kl_penalty - entropy_bonus</span>
<span class="line">    <span class="hl-keyword">return</span> total_loss</span></code></pre>

</figure>

    <h1>
    <a href="#Direct-Preference-Optimization-DPO"><span>Direct Preference Optimization (DPO)</span> <time datetime="2025-02-06">Feb 6, 2025</time></a>
    </h1>
<p><span>DPO simplifies the training loop by skipping the reinforcement learning (RL) loop entirely.</span>
<span>Rather than estimating rewards and advantages, DPO directly uses human preference data (pairs of preferred vs. dispreferred responses) to adjust the model.</span>
<span>It compares the raw model outputs (logits) between a current model and a reference model (often an earlier, supervised-fine-tuned version) using a loss function similar to binary cross-entropy.</span>
<span>So basically it works as follows:</span></p>
<ol>
<li>
<span>Collect Preference Data: Gather pairs of responses where human judges indicate which response they prefer.</span>
</li>
<li>
<span>Evaluate with Two Models: Compute the logits for both the preferred and dispreferred responses using the current model and a reference model.</span>
</li>
<li>
<span>Compute Log Ratios: Determine the relative “strength” (log probabilities) of preferred versus dispreferred responses.</span>
</li>
<li>
<span>Optimize Directly: Use a loss function that, in effect, makes the current model more likely to generate preferred responses and less likely to generate dispreferred ones—all while staying close to the reference model.</span>
</li>
</ol>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">dpo_loss</span>(<span class="hl-params">policy_logits_preferred, policy_logits_dispreferred,</span></span>
<span class="line"><span class="hl-params">             ref_logits_preferred, ref_logits_dispreferred, beta_kl</span>):</span>
<span class="line">    <span class="hl-comment"># Convert logits to log probabilities (details abstracted)</span></span>
<span class="line">    policy_logprob_preferred = F.log_softmax(policy_logits_preferred, dim=-<span class="hl-number">1</span>).gather(...)</span>
<span class="line">    policy_logprob_dispreferred = F.log_softmax(policy_logits_dispreferred, dim=-<span class="hl-number">1</span>).gather(...)</span>
<span class="line">    ref_policy_logprob_preferred = F.log_softmax(ref_logits_preferred, dim=-<span class="hl-number">1</span>).gather(...)</span>
<span class="line">    ref_policy_logprob_dispreferred = F.log_softmax(ref_logits_dispreferred, dim=-<span class="hl-number">1</span>).gather(...)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># Calculate the log ratio comparing current model differences to reference differences</span></span>
<span class="line">    log_ratio = (policy_logprob_preferred - policy_logprob_dispreferred -</span>
<span class="line">                 (ref_policy_logprob_preferred - ref_policy_logprob_dispreferred))</span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># Convert log ratio into a probability using a logistic function (Bradley-Terry model)</span></span>
<span class="line">    preference_prob = <span class="hl-number">1</span> / (<span class="hl-number">1</span> + np.exp(-beta_kl * log_ratio))</span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># Compute loss as binary cross-entropy (minimizing negative log probability of preferred response)</span></span>
<span class="line">    loss = -np.log(preference_prob + <span class="hl-number">1e-8</span>)</span>
<span class="line">    <span class="hl-keyword">return</span> loss</span></code></pre>

</figure>

    <h1>
    <a href="#Group-Relative-Policy-Optimization-GRPO"><span>Group Relative Policy Optimization (GRPO)</span> <time datetime="2025-02-06">Feb 6, 2025</time></a>
    </h1>
<p><span>GRPO is a twist on PPO that is designed to be leaner and faster—especially for complex reasoning tasks.</span>
<span>Instead of relying on a separate value function (critic) to estimate advantages, GRPO uses a group-based approach:</span>
<span>For a given prompt, a group of responses is generated. These responses are scored using the reward model.</span>
<span>So basically it works as follows:</span>
<span>1. Generate a Group of Responses: For each prompt, sample several responses.</span>
<span>2. Score the Responses: Use a reward model to assign a reward to each response.</span>
<span>3. Compute Group Relative Advantages: Calculate advantages by comparing each response’s reward to the group mean (and optionally normalizing by the standard deviation).</span>
<span>4. Update the Policy: Use a PPO-like objective function that takes these group relative advantages into account.</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">grae_advantages</span>(<span class="hl-params">rewards</span>):</span>
<span class="line">    <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">    Compute Group Relative Advantages by normalizing rewards within a group.</span></span>
<span class="line"><span class="hl-string">    &quot;&quot;&quot;</span></span>
<span class="line">    mean_reward = np.mean(rewards)</span>
<span class="line">    std_reward = np.std(rewards)</span>
<span class="line">    normalized_rewards = (rewards - mean_reward) / (std_reward + <span class="hl-number">1e-8</span>)</span>
<span class="line">    advantages = normalized_rewards  <span class="hl-comment"># Here, advantage = normalized reward</span></span>
<span class="line">    <span class="hl-keyword">return</span> advantages</span></code></pre>

</figure>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">grpo_loss</span>(<span class="hl-params">old_policy_logprobs_group, new_policy_logprobs_group,</span></span>
<span class="line"><span class="hl-params">              group_advantages, kl_penalty_coef, clip_epsilon</span>):</span>
<span class="line">    <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">    Compute the GRPO loss over a group of responses.</span></span>
<span class="line"><span class="hl-string">    &quot;&quot;&quot;</span></span>
<span class="line">    group_loss = <span class="hl-number">0</span></span>
<span class="line">    <span class="hl-comment"># Loop over each response in the group</span></span>
<span class="line">    <span class="hl-keyword">for</span> i <span class="hl-keyword">in</span> <span class="hl-built_in">range</span>(<span class="hl-built_in">len</span>(group_advantages)):</span>
<span class="line">        advantage = group_advantages[i]</span>
<span class="line">        new_policy_logprob = new_policy_logprobs_group[i]</span>
<span class="line">        old_policy_logprob = old_policy_logprobs_group[i]</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Compute the probability ratio for the policy update</span></span>
<span class="line">        ratio = np.exp(new_policy_logprob - old_policy_logprob)</span>
<span class="line">        clipped_ratio = np.clip(ratio, <span class="hl-number">1</span> - clip_epsilon, <span class="hl-number">1</span> + clip_epsilon)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Surrogate objective with clipping, similar to PPO</span></span>
<span class="line">        surrogate_objective = np.minimum(ratio * advantage, clipped_ratio * advantage)</span>
<span class="line">        policy_loss = -surrogate_objective</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># KL divergence penalty to restrict too-large updates</span></span>
<span class="line">        kl_divergence = new_policy_logprob - old_policy_logprob</span>
<span class="line">        kl_penalty = kl_penalty_coef * kl_divergence</span>
<span class="line">        </span>
<span class="line">        group_loss += (policy_loss + kl_penalty)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># Average the loss over the group of responses</span></span>
<span class="line">    <span class="hl-keyword">return</span> group_loss / <span class="hl-built_in">len</span>(group_advantages)</span></code></pre>

</figure>
]]></content>
</entry>

<entry>
<title type="text">Deepseek, an overview and quick notes</title>
<link href="https://mbottoni.github.io/2024/12/28/deepseek.html" rel="alternate" type="text/html" title="Deepseek, an overview and quick notes" />
<published>2024-12-28T00:00:00+00:00</published>
<updated>2024-12-28T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2024/12/28/deepseek</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[Some notes of DeepSeek-V3]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2024/12/28/deepseek.html"><![CDATA[
    <h1>
    <a href="#Deepseek-an-overview-and-quick-notes"><span>Deepseek, an overview and quick notes</span> <time datetime="2024-12-28">Dec 28, 2024</time></a>
    </h1>

<figure>

<img alt="" src="/assets/deekseek.webp">
</figure>
<p><span>Some notes of DeepSeek-V3</span></p>
<ul>
<li>
<span>DeepSeek-V3 is a Mixture-of-Experts (MoE) language model with 671B total parameters, of which 37B are activated for each token</span>
</li>
<li>
<span>Uses Multi-head Latent Attention (MLA) for efficient inference and DeepSeekMoE for cost-effective training</span>
</li>
<li>
<span>Introduces an auxiliary-loss-free strategy for load balancing to minimize performance degradation while maintaining balanced expert utilization</span>
</li>
<li>
<span>Implements a multi-token prediction training objective to enhance model performance</span>
</li>
<li>
<span>Trained on 14.8T diverse tokens</span>
</li>
<li>
<span>Uses FP8 mixed precision training with fine-grained quantization strategy</span>
</li>
<li>
<span>Employs DualPipe algorithm for efficient pipeline parallelism with minimal communication overhead</span>
</li>
<li>
<span>Achieves cost-effective training, requiring only 2.788M H800 GPU hours total:</span>
<span>- 2664K hours for pre-training</span>
<span>- 119K hours for context extension </span>
<span>- 5K hours for post-training</span>
<span>- Total cost approximately $5.576M at $2/GPU hour</span>
</li>
<li>
<span>Outperforms other open-source models across multiple benchmarks</span>
</li>
<li>
<span>Particularly strong in:</span>
<span>- Math tasks (90.2% on MATH-500)</span>
<span>- Code tasks (51.6% on Codeforces percentile)</span>
<span>- Knowledge tasks (75.9% on MMLU-Pro)</span>
</li>
<li>
<span>Demonstrates competitive performance against closed-source models like GPT-4 and Claude-3.5-Sonnet</span>
</li>
<li>
<span>Supports context lengths up to 128K tokens through two-stage extension training</span>
</li>
<li>
<span>Auxiliary-loss-free load balancing strategy that improves expert utilization without compromising performance</span>
</li>
<li>
<span>Multi-token prediction training objective that enhances model capabilities while enabling speculative decoding</span>
</li>
<li>
<span>FP8 training framework with tile-wise and block-wise quantization strategies</span>
</li>
<li>
<span>DualPipe algorithm that achieves efficient pipeline parallelism with minimal communication overhead</span>
</li>
</ul>
]]></content>
</entry>

<entry>
<title type="text">Probability Paradigms</title>
<link href="https://mbottoni.github.io/2024/12/23/prob.html" rel="alternate" type="text/html" title="Probability Paradigms" />
<published>2024-12-23T00:00:00+00:00</published>
<updated>2024-12-23T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2024/12/23/prob</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[When we think about probability, there are three 
main philosophical approaches: frequentist, Bayesian, and propensity. Each offers 
a different lens for understanding uncertainty and probability.]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2024/12/23/prob.html"><![CDATA[
    <h1>
    <a href="#Probability-Paradigms"><span>Probability Paradigms</span> <time datetime="2024-12-23">Dec 23, 2024</time></a>
    </h1>
<p><span>When we think about probability, there are three </span>
<span>main philosophical approaches: frequentist, Bayesian, and propensity. Each offers </span>
<span>a different lens for understanding uncertainty and probability.</span></p>
<section id="The-Scenario">

    <h2>
    <a href="#The-Scenario"><span>The Scenario</span> </a>
    </h2>
<p><span>Imagine we</span>&rsquo;<span>re dealing with a new diagnostic test for a rare genetic condition that affects 1 in 1000 people. The test has the following characteristics:</span></p>
<ul>
<li>
<span>If someone has the condition, the test will be positive 99% of the time (sensitivity)</span>
</li>
<li>
<span>If someone doesn</span>&rsquo;<span>t have the condition, the test will be negative 95% of the time (specificity)</span>
</li>
</ul>
<p><span>Now, let</span>&rsquo;<span>s say Sarah gets tested and receives a positive result. What</span>&rsquo;<span>s the probability that she </span>
<span>actually has the condition? Each probability paradigm approaches this question differently.</span></p>
</section>
<section id="The-Frequentist-Approach">

    <h2>
    <a href="#The-Frequentist-Approach"><span>The Frequentist Approach</span> </a>
    </h2>
<p><span>The frequentist views probability as the long-run frequency of events in repeated trials. They might say:</span></p>
<p>&ldquo;<span>If we were to run this test on a very large number of people, and look only at </span>
<span>the positive test results, what proportion of those people would actually have the condition?</span>&rdquo;</p>
<p><span>The frequentist would focus on the sampling distribution and confidence intervals. They might </span>
<span>resist making a direct probability statement about Sarah</span>&rsquo;<span>s individual case, arguing that she </span>
<span>either has the condition or doesn</span>&rsquo;<span>t – there</span>&rsquo;<span>s no probability about it. Instead, they </span>
<span>would frame their analysis in terms of error rates and long-term frequencies.</span></p>
<p><span>In this case, they would calculate the false positive and true positive rates across a hypothetical population:</span></p>
<ul>
<li>
<span>In 1000 people, 1 person would have the condition</span>
</li>
<li>
<span>That 1 person would test positive 99% of the time = 0.99 true positives</span>
</li>
<li>
<span>The 999 people without the condition would test positive 5% of the time = 49.95 false positives</span>
</li>
<li>
<span>Total positive tests = 50.94</span>
</li>
<li>
<span>Proportion of positive tests that are true positives ≈ 1.94%</span>
</li>
</ul>
</section>
<section id="The-Bayesian-Approach">

    <h2>
    <a href="#The-Bayesian-Approach"><span>The Bayesian Approach</span> </a>
    </h2>
<p><span>The Bayesian sees probability as a degree of belief that gets updated with </span>
<span>new evidence. They would start with a prior probability (the base </span>
<span>rate of 1/1000) and update it with the new </span>
<span>evidence (the positive test result) using Bayes</span>&rsquo;<span> Theorem.</span></p>
<p><span>The Bayesian would say: </span>&ldquo;<span>Before the test, we believed Sarah had a 0.1% chance </span>
<span>of having the condition. The positive test result gives us new information </span>
<span>to update this belief.</span>&rdquo;</p>
<p><span>Using Bayes</span>&rsquo;<span> Theorem:</span>
<span>P(Condition|Positive) = P(Positive|Condition) × P(Condition) / P(Positive)</span>
<span>= 0.99 × 0.001 / (0.99 × 0.001 + 0.05 × 0.999)</span>
<span>≈ 0.0194 or about 1.94%</span></p>
<p><span>The Bayesian is comfortable making a direct probability statement about Sarah</span>
&lsquo;<span>s specific case, saying there</span>&rsquo;<span>s a 1.94% chance she has the condition.</span></p>
</section>
<section id="The-Propensity-Approach">

    <h2>
    <a href="#The-Propensity-Approach"><span>The Propensity Approach</span> </a>
    </h2>
<p><span>The propensity theorist views probability as an objective </span>
<span>physical property – a tendency or disposition of a </span>
<span>system to produce certain outcomes. They might say:</span></p>
<p>&ldquo;<span>The test result reflects the physical properties of Sarah</span>&rsquo;<span>s </span>
<span>genes and the testing mechanism. The probability emerges from </span>
<span>the actual physical setup of the situation.</span>&rdquo;</p>
<p><span>They would focus on the causal mechanisms involved: the biological </span>
<span>factors that cause the condition, the chemical reactions in the test, and how </span>
<span>these physical properties interact to produce results. They might analyze the </span>
<span>molecular basis of the test</span>&rsquo;<span>s accuracy and how it interacts with the genetic markers it</span>&rsquo;<span>s designed to detect.</span></p>
<p><span>These different approaches can lead to different practical recommendations:</span></p>
<ul>
<li>
<p><span>A frequentist might emphasize the need for additional testing, pointing out that in a large population, most positive results are false positives.</span></p>
</li>
<li>
<p><span>A Bayesian might focus on gathering more prior information about Sarah (family history, symptoms, etc.) to refine the probability estimate.</span></p>
</li>
<li>
<p><span>A propensity theorist might advocate for understanding the biological mechanism better, perhaps recommending a different type of test that targets the condition</span>&rsquo;<span>s physical manifestations more directly.</span></p>
</li>
</ul>
</section>
]]></content>
</entry>

<entry>
<title type="text">Classifier free diffusion guidance</title>
<link href="https://mbottoni.github.io/2024/12/15/cfg.html" rel="alternate" type="text/html" title="Classifier free diffusion guidance" />
<published>2024-12-15T00:00:00+00:00</published>
<updated>2024-12-15T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2024/12/15/cfg</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[One of the key techniques in diffusion models that has significantly improved their performance is 
classifier-free guidance. In this post, we'll explore what classifier-free 
guidance is, how it works, and implement it from scratch in PyTorch.]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2024/12/15/cfg.html"><![CDATA[
    <h1>
    <a href="#Classifier-free-diffusion-guidance"><span>Classifier free diffusion guidance</span> <time datetime="2024-12-15">Dec 15, 2024</time></a>
    </h1>
<p><span>One of the key techniques in diffusion models that has significantly improved their performance is </span>
<span>classifier-free guidance. In this post, we</span>&rsquo;<span>ll explore what classifier-free </span>
<span>guidance is, how it works, and implement it from scratch in PyTorch.</span></p>
<section id="What-is-Classifier-Free-Guidance">

    <h2>
    <a href="#What-is-Classifier-Free-Guidance"><span>What is Classifier-Free Guidance?</span> </a>
    </h2>
<p><span>At its core, classifier-free guidance is an elegant technique that allows us to </span>
<span>control the generation process of diffusion models without requiring a </span>
<span>separate classifier. The key insight is that we can create a more powerful conditional generation </span>
<span>process by combining both conditional and unconditional generation in a clever way.</span></p>
<p><span>Think of it like having two artists working together:</span></p>
<ol>
<li>
<span>One artist (conditional model) who follows specific instructions</span>
</li>
<li>
<span>One artist (unconditional model) who creates freely without constraints</span>
</li>
</ol>
<p><span>By combining their perspectives with different weights, we can create results </span>
<span>that are both high-quality and well-aligned with our desired conditions.</span></p>
</section>
<section id="The-Mathematics-Behind-Classifier-Free-Guidance">

    <h2>
    <a href="#The-Mathematics-Behind-Classifier-Free-Guidance"><span>The Mathematics Behind Classifier-Free Guidance</span> </a>
    </h2>
<p><span>The core equation for classifier-free guidance is surprisingly simple:</span></p>

<figure class="code-block">


<pre><code><span class="line">ε̃ = (1 + w) * εθ(zt, c) - w * εθ(zt, ∅)</span></code></pre>

</figure>
<p><span>Where:</span>
<span>- ε̃ is the guided noise prediction</span>
<span>- w is the guidance weight</span>
<span>- εθ(zt, c) is the conditional model prediction</span>
<span>- εθ(zt, ∅) is the unconditional model prediction</span></p>
<p><span>The beauty of this approach is that it doesn</span>&rsquo;<span>t require training </span>
<span>two separate models. Instead, we train a single model that can </span>
<span>handle both conditional and unconditional generation.</span></p>
</section>
<section id="Implementation-A-Complete-Example">

    <h2>
    <a href="#Implementation-A-Complete-Example"><span>Implementation: A Complete Example</span> </a>
    </h2>
<p><span>Let</span>&rsquo;<span>s implement classifier-free guidance for a diffusion model from </span>
<span>scratch. We</span>&rsquo;<span>ll build a system that can generate MNIST-like digits conditioned on class labels.</span></p>
<p><span>First, let</span>&rsquo;<span>s create our improved diffusion model:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">import</span> torch</span>
<span class="line"><span class="hl-keyword">import</span> torch.nn <span class="hl-keyword">as</span> nn</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">class</span> <span class="hl-title class_">DiffusionModel</span>(nn.Module):</span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">__init__</span>(<span class="hl-params">self, input_dim=<span class="hl-number">784</span>, hidden_dim=<span class="hl-number">256</span>, num_classes=<span class="hl-number">10</span></span>):</span>
<span class="line">        <span class="hl-built_in">super</span>().__init__()</span>
<span class="line">        self.input_dim = input_dim</span>
<span class="line">        self.num_classes = num_classes</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Improved embedding with position encoding</span></span>
<span class="line">        self.class_embedding = nn.Sequential(</span>
<span class="line">            nn.Embedding(num_classes + <span class="hl-number">1</span>, hidden_dim),  <span class="hl-comment"># +1 for unconditional</span></span>
<span class="line">            nn.Linear(hidden_dim, hidden_dim),</span>
<span class="line">            nn.ReLU()</span>
<span class="line">        )</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Time embedding</span></span>
<span class="line">        self.time_embed = nn.Sequential(</span>
<span class="line">            nn.Linear(<span class="hl-number">1</span>, hidden_dim),</span>
<span class="line">            nn.ReLU(),</span>
<span class="line">            nn.Linear(hidden_dim, hidden_dim)</span>
<span class="line">        )</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Enhanced U-Net architecture</span></span>
<span class="line">        self.encoder = nn.Sequential(</span>
<span class="line">            nn.Linear(input_dim + hidden_dim * <span class="hl-number">2</span>, hidden_dim * <span class="hl-number">2</span>),</span>
<span class="line">            nn.LayerNorm(hidden_dim * <span class="hl-number">2</span>),</span>
<span class="line">            nn.ReLU(),</span>
<span class="line">            nn.Linear(hidden_dim * <span class="hl-number">2</span>, hidden_dim),</span>
<span class="line">            nn.LayerNorm(hidden_dim),</span>
<span class="line">            nn.ReLU()</span>
<span class="line">        )</span>
<span class="line">        </span>
<span class="line">        self.decoder = nn.Sequential(</span>
<span class="line">            nn.Linear(hidden_dim, hidden_dim * <span class="hl-number">2</span>),</span>
<span class="line">            nn.LayerNorm(hidden_dim * <span class="hl-number">2</span>),</span>
<span class="line">            nn.ReLU(),</span>
<span class="line">            nn.Linear(hidden_dim * <span class="hl-number">2</span>, input_dim),</span>
<span class="line">            nn.Tanh()  <span class="hl-comment"># Bounded output</span></span>
<span class="line">        )</span>
<span class="line">        </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">forward</span>(<span class="hl-params">self, x, t, c=<span class="hl-literal">None</span></span>):</span>
<span class="line">        batch_size = x.shape[<span class="hl-number">0</span>]</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Handle conditional vs unconditional</span></span>
<span class="line">        <span class="hl-keyword">if</span> c <span class="hl-keyword">is</span> <span class="hl-literal">None</span>:</span>
<span class="line">            c = torch.full((batch_size,), self.num_classes, device=x.device)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Get embeddings</span></span>
<span class="line">        c_emb = self.class_embedding(c)</span>
<span class="line">        t_emb = self.time_embed(t.unsqueeze(-<span class="hl-number">1</span>))</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Combine all information</span></span>
<span class="line">        x_c = torch.cat([x, c_emb, t_emb], dim=-<span class="hl-number">1</span>)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Forward pass</span></span>
<span class="line">        h = self.encoder(x_c)</span>
<span class="line">        output = self.decoder(h)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-keyword">return</span> output</span></code></pre>

</figure>
<p><span>Now, let</span>&rsquo;<span>s implement an improved training loop with classifier-free guidance:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">train_diffusion_model</span>(<span class="hl-params">model, dataloader, num_epochs=<span class="hl-number">100</span>, puncond=<span class="hl-number">0.1</span>, device=<span class="hl-string">&#x27;cuda&#x27;</span></span>):</span>
<span class="line">    <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">    Enhanced training loop with classifier-free guidance support</span></span>
<span class="line"><span class="hl-string">    &quot;&quot;&quot;</span></span>
<span class="line">    optimizer = torch.optim.AdamW(model.parameters(), lr=<span class="hl-number">1e-4</span>, weight_decay=<span class="hl-number">0.01</span>)</span>
<span class="line">    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">for</span> epoch <span class="hl-keyword">in</span> <span class="hl-built_in">range</span>(num_epochs):</span>
<span class="line">        model.train()</span>
<span class="line">        total_loss = <span class="hl-number">0</span></span>
<span class="line">        </span>
<span class="line">        <span class="hl-keyword">for</span> batch, (x, c) <span class="hl-keyword">in</span> <span class="hl-built_in">enumerate</span>(dataloader):</span>
<span class="line">            batch_size = x.shape[<span class="hl-number">0</span>]</span>
<span class="line">            x = x.to(device)</span>
<span class="line">            c = c.to(device)</span>
<span class="line">            </span>
<span class="line">            <span class="hl-comment"># Sample timesteps</span></span>
<span class="line">            t = torch.rand(batch_size, device=device)</span>
<span class="line">            </span>
<span class="line">            <span class="hl-comment"># Create noise</span></span>
<span class="line">            epsilon = torch.randn_like(x)</span>
<span class="line">            z_t = alpha(t).view(-<span class="hl-number">1</span>, <span class="hl-number">1</span>) * x + sigma(t).view(-<span class="hl-number">1</span>, <span class="hl-number">1</span>) * epsilon</span>
<span class="line">            </span>
<span class="line">            <span class="hl-comment"># Sometimes drop conditioning for unconditional training</span></span>
<span class="line">            mask = torch.rand(batch_size, device=device) &lt; puncond</span>
<span class="line">            c_in = torch.where(mask, torch.full_like(c, model.num_classes), c)</span>
<span class="line">            </span>
<span class="line">            <span class="hl-comment"># Get model prediction</span></span>
<span class="line">            epsilon_theta = model(z_t, t, c_in)</span>
<span class="line">            </span>
<span class="line">            <span class="hl-comment"># Compute loss with improved weighting</span></span>
<span class="line">            loss = torch.nn.functional.mse_loss(epsilon_theta, epsilon, reduction=<span class="hl-string">&#x27;none&#x27;</span>)</span>
<span class="line">            loss = loss * (<span class="hl-number">1</span> + t.view(-<span class="hl-number">1</span>, <span class="hl-number">1</span>))  <span class="hl-comment"># Weight loss by timestep</span></span>
<span class="line">            loss = loss.mean()</span>
<span class="line">            </span>
<span class="line">            optimizer.zero_grad()</span>
<span class="line">            loss.backward()</span>
<span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="hl-number">1.0</span>)</span>
<span class="line">            optimizer.step()</span>
<span class="line">            </span>
<span class="line">            total_loss += loss.item()</span>
<span class="line">            </span>
<span class="line">        scheduler.step()</span>
<span class="line">        avg_loss = total_loss / <span class="hl-built_in">len</span>(dataloader)</span>
<span class="line">        <span class="hl-built_in">print</span>(<span class="hl-string">f&quot;Epoch <span class="hl-subst">{epoch}</span>: Average Loss = <span class="hl-subst">{avg_loss:<span class="hl-number">.4</span>f}</span>&quot;</span>)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">return</span> model</span></code></pre>

</figure>
<p><span>Finally, let</span>&rsquo;<span>s improve the sampling process with classifier-free guidance:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">sample_with_guidance</span>(<span class="hl-params">model, c, w, steps=<span class="hl-number">50</span>, data_shape=[<span class="hl-number">1</span>, <span class="hl-number">28</span>, <span class="hl-number">28</span>], device=<span class="hl-string">&#x27;cuda&#x27;</span></span>):</span>
<span class="line">    <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">    Enhanced sampling with classifier-free guidance</span></span>
<span class="line"><span class="hl-string">    &quot;&quot;&quot;</span></span>
<span class="line">    model.<span class="hl-built_in">eval</span>()</span>
<span class="line">    batch_size = <span class="hl-number">1</span></span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># Create log-SNR sequence with improved spacing</span></span>
<span class="line">    lambda_sequence = torch.linspace(<span class="hl-number">0</span>, <span class="hl-number">1</span>, steps)</span>
<span class="line">    lambda_sequence = torch.sigmoid(<span class="hl-number">10</span> * (lambda_sequence - <span class="hl-number">0.5</span>))  <span class="hl-comment"># Better spacing</span></span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># Initialize with noise</span></span>
<span class="line">    z_t = torch.randn(batch_size, *data_shape, device=device)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-comment"># Prepare conditioning</span></span>
<span class="line">    c = torch.tensor([c], device=device)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">with</span> torch.no_grad():</span>
<span class="line">        <span class="hl-keyword">for</span> i <span class="hl-keyword">in</span> <span class="hl-built_in">range</span>(<span class="hl-built_in">len</span>(lambda_sequence) - <span class="hl-number">1</span>):</span>
<span class="line">            lambda_t = lambda_sequence[i]</span>
<span class="line">            lambda_next = lambda_sequence[i + <span class="hl-number">1</span>]</span>
<span class="line">            </span>
<span class="line">            <span class="hl-comment"># Get conditional and unconditional score estimates</span></span>
<span class="line">            epsilon_theta_c = model(z_t, lambda_t, c)</span>
<span class="line">            epsilon_theta = model(z_t, lambda_t, <span class="hl-literal">None</span>)</span>
<span class="line">            </span>
<span class="line">            <span class="hl-comment"># Apply classifier-free guidance</span></span>
<span class="line">            epsilon_guided = (<span class="hl-number">1</span> + w) * epsilon_theta_c - w * epsilon_theta</span>
<span class="line">            </span>
<span class="line">            <span class="hl-comment"># Improved DDIM-like step</span></span>
<span class="line">            x_pred = (z_t - sigma(lambda_t).view(-<span class="hl-number">1</span>, <span class="hl-number">1</span>, <span class="hl-number">1</span>) * epsilon_guided) / alpha(lambda_t).view(-<span class="hl-number">1</span>, <span class="hl-number">1</span>, <span class="hl-number">1</span>)</span>
<span class="line">            z_t = alpha(lambda_next).view(-<span class="hl-number">1</span>, <span class="hl-number">1</span>, <span class="hl-number">1</span>) * x_pred + sigma(lambda_next).view(-<span class="hl-number">1</span>, <span class="hl-number">1</span>, <span class="hl-number">1</span>) * epsilon_guided</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">return</span> z_t[<span class="hl-number">0</span>]</span></code></pre>

</figure>
</section>
<section id="Understanding-the-Improvements">

    <h2>
    <a href="#Understanding-the-Improvements"><span>Understanding the Improvements</span> </a>
    </h2>
<p><span>Our implementation includes several key improvements over the basic version:</span></p>
<ol>
<li>
<p><strong><strong><span>Enhanced Architecture</span></strong></strong><span>:</span>
<span>- Added time embeddings for better temporal understanding</span>
<span>- Included layer normalization for stable training</span>
<span>- Added residual connections in the U-Net structure</span></p>
</li>
<li>
<p><strong><strong><span>Improved Training</span></strong></strong><span>:</span>
<span>- Using AdamW optimizer with weight decay for better regularization</span>
<span>- Implemented learning rate scheduling</span>
<span>- Added gradient clipping to prevent exploding gradients</span>
<span>- Weighted loss by timestep to focus more on later denoising steps</span></p>
</li>
<li>
<p><strong><strong><span>Better Sampling</span></strong></strong><span>:</span>
<span>- Improved timestep spacing using sigmoid scaling</span>
<span>- More stable DDIM-like stepping procedure</span>
<span>- Better handling of batch dimensions</span></p>
</li>
</ol>
</section>
]]></content>
</entry>

<entry>
<title type="text">Diffusion models for time series</title>
<link href="https://mbottoni.github.io/2024/12/07/timeseries-diffusion.html" rel="alternate" type="text/html" title="Diffusion models for time series" />
<published>2024-12-07T00:00:00+00:00</published>
<updated>2024-12-07T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2024/12/07/timeseries-diffusion</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[On this post I will explore the main findings from the paper UTSD: Unified Time Series Diffusion Model and an explanation 
of the content. For more details here is the link to the paper Link to paper]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2024/12/07/timeseries-diffusion.html"><![CDATA[
    <h1>
    <a href="#Diffusion-models-for-time-series"><span>Diffusion models for time series</span> <time datetime="2024-12-07">Dec 7, 2024</time></a>
    </h1>
<p><span>On this post I will explore the main findings from the paper </span>&ldquo;<span>UTSD: Unified Time Series Diffusion Model</span>&rdquo;<span> and an explanation </span>
<span>of the content. For more details here is the link to the paper </span><a href="https://arxiv.org/pdf/2412.03068.pdf"><span>Link to paper</span></a></p>
<section id="Summary-of-Findings-from-UTSD-Paper">

    <h2>
    <a href="#Summary-of-Findings-from-UTSD-Paper"><span>Summary of Findings from UTSD Paper</span> </a>
    </h2>
<p><span>The authors of the paper propose a novel architecture, UTSD, for time </span>
<span>series analysis. The researchers note the prevalence of time series </span>
<span>data in a variety of real world applications. They also point out that </span>
<span>data across different domains often have different statistical properties. They posit that this </span>
<span>creates a challenge to the generalizability and robustness of time </span>
<span>series analysis. In order to address this, the authors propose a unified time </span>
<span>series diffusion model. The paper explains that the UTSD model </span>
<span>uses a diffusion denoising process, in contrast to autoregressive models, to model </span>
<span>the mixture distribution of cross-domain data and generate a prediction sequence for </span>
<span>the target domain. The model learns from time series data across a range of domains </span>
<span>with the goal of having strong generalization capabilities and robustness to achieve zero-shot </span>
<span>inference on unseen domains. UTSD consists of three key designs:</span></p>
<ul>
<li>
<span>Condition-denoising architecture</span>
</li>
<li>
<span>Reverse noise reduction process in the actual sequence space</span>
</li>
<li>
<span>Conditional generation strategy based on improved classifier-free guidance</span>
</li>
</ul>
<p><span>The paper reports that UTSD outperforms existing foundation models on all data domains. It achieves an average </span>
<span>MSE reduction of 14.2%, 20.1%, and 27.6% compared to the existing Moirai, UniTime, and GPT4TS, respectively. The paper also </span>
<span>reports that UTSD, when trained from scratch, achieves comparable performance to domain-specific models. In the paper, the authors </span>
<span>contend that UTSD shows stable and reliable time series generation which indicates the </span>
<span>model</span>&rsquo;<span>s potential as a foundational model for time series analysis.</span></p>
</section>
<section id="Explanation-of-the-Paper">

    <h2>
    <a href="#Explanation-of-the-Paper"><span>Explanation of the Paper</span> </a>
    </h2>
<p><span>The paper presents a detailed explanation of the UTSD model architecture and its three key design elements. These designs aim </span>
<span>to address the challenges of modeling probability distributions across multiple time series domains and generating accurate </span>
<span>long-term forecasts.</span></p>

<figure>

<img alt="" src="/assets/time-series-diffusion.png">
</figure>
<section id="1-Condition-Denoising-Architecture">

    <h3>
    <a href="#1-Condition-Denoising-Architecture"><span>1. Condition-Denoising Architecture</span> </a>
    </h3>
<p><span>This architecture includes a Condition Net and a Denoising Net. The Condition Net learns multi-scale </span>
<span>representations of temporal fluctuation patterns from different time series domains. These representations </span>
<span>are then used as conditional variables to guide the Denoising Net in generating the prediction sequence. The paper argues </span>
<span>that capturing multi-scale representations is crucial because time series from various domains often exhibit different latent patterns.</span></p>
</section>
<section id="2-Reverse-Noise-Reduction-in-Actual-Sequence-Space">

    <h3>
    <a href="#2-Reverse-Noise-Reduction-in-Actual-Sequence-Space"><span>2. Reverse Noise Reduction in Actual Sequence Space</span> </a>
    </h3>
<p><span>UTSD performs the reverse noise reduction process directly in the actual sequence space, unlike traditional </span>
<span>diffusion models that operate in a latent space. This design choice is justified by the fact that iterative </span>
<span>denoising in the latent space can lead to error accumulation, which is amplified when aligning </span>
<span>the latent space back to the actual sequence space.</span></p>
</section>
<section id="3-Improved-Classifier-Free-Guidance">

    <h3>
    <a href="#3-Improved-Classifier-Free-Guidance"><span>3. Improved Classifier-Free Guidance</span> </a>
    </h3>
<p><span>The UTSD model uses an improved classifier-free guidance strategy to ensure strong generalization ability. This strategy leverages the multi-scale </span>
<span>representation captured by the Condition Net as a conditional variable to guide the reconstruction of the forecast from Gaussian noise.</span></p>
</section>
<section id="Additional-Architectural-Components">

    <h3>
    <a href="#Additional-Architectural-Components"><span>Additional Architectural Components</span> </a>
    </h3>
<ul>
<li>
<strong><strong><span>Transfer-Adapter Module:</span></strong></strong><span> This module allows for efficient fine-tuning of the pre-trained UTSD model on specific downstream tasks. It transforms </span>
<span>the fluctuation patterns learned during pre-training into the latent space of the target domain, enabling the generation of domain-specific time series samples.</span>
</li>
<li>
<strong><strong><span>Blocks Implementation:</span></strong></strong><span> The Condition Net and Denoising Net are built using ResNet1D and Transformer1D modules. The ResNet1D modules handle </span>
<span>the embedding of diffusion timesteps and latent representations, while the Transformer1D modules capture dependencies within the observation sequence and leverage historical fluctuation patterns as context for denoising.</span>
</li>
</ul>
</section>
</section>
]]></content>
</entry>

<entry>
<title type="text">Flow Matching, a short overview</title>
<link href="https://mbottoni.github.io/2024/12/01/flow.html" rel="alternate" type="text/html" title="Flow Matching, a short overview" />
<published>2024-12-01T00:00:00+00:00</published>
<updated>2024-12-01T00:00:00+00:00</updated>
<id>https://mbottoni.github.io/2024/12/01/flow</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[In summary, flow matching is a generative modeling technique that provides 
an elegant way to transform data distributions.]]></summary>
<content type="html" xml:base="https://mbottoni.github.io/2024/12/01/flow.html"><![CDATA[
    <h1>
    <a href="#Flow-Matching-a-short-overview"><span>Flow Matching, a short overview</span> <time datetime="2024-12-01">Dec 1, 2024</time></a>
    </h1>

<figure>

<img alt="" src="/assets/flow.png">
</figure>
<p><span>In summary, flow matching is a generative modeling technique that provides </span>
<span>an elegant way to transform data distributions.</span></p>

<figure class="code-block">


<pre><code><span class="line"></span>
<span class="line"><span class="hl-keyword">import</span> numpy <span class="hl-keyword">as</span> np</span>
<span class="line"><span class="hl-keyword">import</span> torch</span>
<span class="line"><span class="hl-keyword">import</span> torch.nn <span class="hl-keyword">as</span> nn</span>
<span class="line"><span class="hl-keyword">import</span> torch.optim <span class="hl-keyword">as</span> optim</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">class</span> <span class="hl-title class_">FlowMatchingModel</span>:</span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">__init__</span>(<span class="hl-params">self, input_dim, hidden_dim</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Initialize Flow Matching Model</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            input_dim (int): Dimension of input data</span></span>
<span class="line"><span class="hl-string">            hidden_dim (int): Dimension of hidden layers</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        self.base_distribution = <span class="hl-literal">None</span>  <span class="hl-comment"># Initial data distribution</span></span>
<span class="line">        self.target_distribution = <span class="hl-literal">None</span>  <span class="hl-comment"># Target data distribution</span></span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Neural network to learn the flow</span></span>
<span class="line">        self.flow_network = nn.Sequential(</span>
<span class="line">            nn.Linear(input_dim + <span class="hl-number">1</span>, hidden_dim),  <span class="hl-comment"># +1 for time conditioning</span></span>
<span class="line">            nn.ReLU(),</span>
<span class="line">            nn.Linear(hidden_dim, hidden_dim),</span>
<span class="line">            nn.ReLU(),</span>
<span class="line">            nn.Linear(hidden_dim, input_dim)</span>
<span class="line">        )</span>
<span class="line">        </span>
<span class="line">        self.optimizer = optim.Adam(self.flow_network.parameters())</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">sample_base_distribution</span>(<span class="hl-params">self, num_samples</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Sample from the base (initial) distribution</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            num_samples (int): Number of samples to generate</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Samples from base distribution</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-comment"># Example: Gaussian distribution</span></span>
<span class="line">        <span class="hl-keyword">return</span> torch.randn(num_samples, self.input_dim)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">probability_flow_ode</span>(<span class="hl-params">self, x, t</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Compute the probability flow ODE</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            x (torch.Tensor): Current data point</span></span>
<span class="line"><span class="hl-string">            t (torch.Tensor): Time variable</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Flow direction</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-comment"># Combine input and time as network input</span></span>
<span class="line">        network_input = torch.cat([x, t], dim=<span class="hl-number">1</span>)</span>
<span class="line">        <span class="hl-keyword">return</span> self.flow_network(network_input)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">conditional_vector_field</span>(<span class="hl-params">self, x0, x1, t</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Compute the conditional vector field</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            x0 (torch.Tensor): Initial data point</span></span>
<span class="line"><span class="hl-string">            x1 (torch.Tensor): Target data point</span></span>
<span class="line"><span class="hl-string">            t (torch.Tensor): Time variable</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Conditional vector field</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-comment"># Interpolate between source and target</span></span>
<span class="line">        x_t = x0 * (<span class="hl-number">1</span> - t) + x1 * t</span>
<span class="line">        vector_field = x1 - x0</span>
<span class="line">        <span class="hl-keyword">return</span> vector_field</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">loss_function</span>(<span class="hl-params">self, x0, x1</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Compute the flow matching loss</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            x0 (torch.Tensor): Initial data points</span></span>
<span class="line"><span class="hl-string">            x1 (torch.Tensor): Target data points</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Training loss</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        batch_size = x0.shape[<span class="hl-number">0</span>]</span>
<span class="line">        t = torch.rand(batch_size, <span class="hl-number">1</span>)  <span class="hl-comment"># Random time sampling</span></span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Compute vector field</span></span>
<span class="line">        true_vector_field = self.conditional_vector_field(x0, x1, t)</span>
<span class="line">        predicted_vector_field = self.probability_flow_ode(x0, t)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Compute MSE loss between true and predicted vector fields</span></span>
<span class="line">        loss = torch.mean((predicted_vector_field - true_vector_field) ** <span class="hl-number">2</span>)</span>
<span class="line">        <span class="hl-keyword">return</span> loss</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">train</span>(<span class="hl-params">self, dataloader, epochs</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Train the Flow Matching Model</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            dataloader (torch.utils.data.DataLoader): Training data</span></span>
<span class="line"><span class="hl-string">            epochs (int): Number of training epochs</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-keyword">for</span> epoch <span class="hl-keyword">in</span> <span class="hl-built_in">range</span>(epochs):</span>
<span class="line">            <span class="hl-keyword">for</span> batch_x0, batch_x1 <span class="hl-keyword">in</span> dataloader:</span>
<span class="line">                self.optimizer.zero_grad()</span>
<span class="line">                loss = self.loss_function(batch_x0, batch_x1)</span>
<span class="line">                loss.backward()</span>
<span class="line">                self.optimizer.step()</span>
<span class="line">            </span>
<span class="line">            <span class="hl-built_in">print</span>(<span class="hl-string">f&quot;Epoch <span class="hl-subst">{epoch+<span class="hl-number">1</span>}</span>/<span class="hl-subst">{epochs}</span>, Loss: <span class="hl-subst">{loss.item()}</span>&quot;</span>)</span>
<span class="line">    </span>
<span class="line">    <span class="hl-keyword">def</span> <span class="hl-title function_">generate_samples</span>(<span class="hl-params">self, num_samples</span>):</span>
<span class="line">        <span class="hl-string">&quot;&quot;&quot;</span></span>
<span class="line"><span class="hl-string">        Generate new samples using the learned flow</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Args:</span></span>
<span class="line"><span class="hl-string">            num_samples (int): Number of samples to generate</span></span>
<span class="line"><span class="hl-string">        </span></span>
<span class="line"><span class="hl-string">        Returns:</span></span>
<span class="line"><span class="hl-string">            torch.Tensor: Generated samples</span></span>
<span class="line"><span class="hl-string">        &quot;&quot;&quot;</span></span>
<span class="line">        <span class="hl-comment"># Start from base distribution and follow the learned flow</span></span>
<span class="line">        x0 = self.sample_base_distribution(num_samples)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-comment"># Perform sampling through ODE solving</span></span>
<span class="line">        x_generated = x0  <span class="hl-comment"># Starting point</span></span>
<span class="line">        time_steps = torch.linspace(<span class="hl-number">0</span>, <span class="hl-number">1</span>, <span class="hl-number">100</span>)</span>
<span class="line">        </span>
<span class="line">        <span class="hl-keyword">for</span> t <span class="hl-keyword">in</span> time_steps[<span class="hl-number">1</span>:]:</span>
<span class="line">            vector_field = self.probability_flow_ode(x_generated, t)</span>
<span class="line">            x_generated += vector_field * (time_steps[<span class="hl-number">1</span>] - time_steps[<span class="hl-number">0</span>])</span>
<span class="line">        </span>
<span class="line">        <span class="hl-keyword">return</span> x_generated</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">def</span> <span class="hl-title function_">main</span>():</span>
<span class="line">    <span class="hl-comment"># Hyperparameters</span></span>
<span class="line">    input_dim = <span class="hl-number">10</span></span>
<span class="line">    hidden_dim = <span class="hl-number">64</span></span>
<span class="line">    num_epochs = <span class="hl-number">100</span></span>
<span class="line">    </span>
<span class="line">    flow_matching = FlowMatchingModel(input_dim, hidden_dim)</span>
<span class="line">    flow_matching.train(dataloader, num_epochs)</span>
<span class="line">    generated_samples = flow_matching.generate_samples(<span class="hl-number">1000</span>)</span></code></pre>

</figure>
]]></content>
</entry>

</feed>
